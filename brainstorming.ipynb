{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d5a94bd2-a922-4b01-a9b9-7658e41f6036",
            "metadata": {},
            "source": [
                "# Aufbau der Notebooks [Philipp]\n",
                "\n",
                "- Multivalue bei Notebooks angucken\n",
                "- Wie installiere ich den \"scheiß\"\n",
                "- Widgets: https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "d3394772",
            "metadata": {},
            "outputs": [],
            "source": [
                "from enum import Enum\n",
                "import ipywidgets as widgets\n",
                "from pandas import read_csv\n",
                "import pandas as pd\n",
                "import asammdf\n",
                "from IPython.display import display\n",
                "import os\n",
                "import numpy as np\n",
                "import time\n",
                "import pathlib as pl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "id": "268ea6b8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "de7ee4739a6c447f8d612ae305d28733",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "TagsInput(value=['TEST_NAME', 'TEST_TYPE', 'RPM', 'FLOW_RATE', 'P1', 'P2'], allow_duplicates=False, allowed_ta…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Globals\n",
                "\n",
                "PATH_RAW_DATA = \"./data/raw/\"\n",
                "PATH_FEATURE_DATA = \"./data/\"\n",
                "PATH_EXPLORATION_DATA = \"./exploration/\"\n",
                "PATH_MODEL = \"./models/\"\n",
                "DATA_SOURCE_KIDAQ = [\"TEST_NAME\", \"TEST_TYPE\", \"RPM\", \"FLOW_RATE\", \"P1\", \"P2\"]\n",
                "RAW_DATA_TYPE = [\"KIDAQ\", \"VIB\"]\n",
                "\n",
                "DATA_SOURCE_VID = [\n",
                "    \"TEST_NAME\",\n",
                "    \"TEST_TYPE\",\n",
                "    \"RPM\",\n",
                "    \"FLOW_RATE\",\n",
                "    \"S1\",\n",
                "    \"S2\",\n",
                "    \"S3\",\n",
                "    \"S4\",\n",
                "    \"S5\",\n",
                "    \"S6\",\n",
                "    \"S7\",\n",
                "    \"S8\",\n",
                "]\n",
                "FEATURE = [\n",
                "    \"STD\",\n",
                "    \"RANGE\",\n",
                "    \"IQR\",\n",
                "    \"MEAN_MEDIAN\",\n",
                "    \"FFT\",\n",
                "]\n",
                "OPERATING_POINT_FREQ = [725, 1450, 2175, 2900]\n",
                "OPERATING_POINT_FLOW_RATE = [0, 25, 50, 75, 100]\n",
                "\n",
                "LEARNER = Enum(\"LEARNER\", [\"DNN\", \"DT\"])\n",
                "\n",
                "DEFAULT_LEARNER = LEARNER.DNN\n",
                "DEFAULT_RAW_DATA_TYPE = RAW_DATA_TYPE[0]\n",
                "DEFAULT_RAW_DATA = DATA_SOURCE_KIDAQ\n",
                "\n",
                "DEFAULT_CLASS_LABEL = \"TEST_TYPE\"\n",
                "\n",
                "tags = widgets.TagsInput(\n",
                "    value=DEFAULT_RAW_DATA, allowed_tags=DEFAULT_RAW_DATA, allow_duplicates=False\n",
                ")\n",
                "display(tags)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1eaf4db6",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "d08d88a7-0fc1-4c7a-91f7-df5aa0a4f9a2",
            "metadata": {},
            "source": [
                "## 1. Aufgabe und Daten erklären/beschreiben [Philipp]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6efc6220-a14b-4ff0-b0d8-66ba17569050",
            "metadata": {},
            "source": [
                "## 3. Preprocessing [Valerij]\n",
                "\n",
                "Aufgeteilt nach KIDAQ und VIB (separat um es einfach zu halten)\n",
                "\n",
                "- Auswahl der Fenstergröße in Millisekunden\n",
                "- Auswahl der Abtastrate\n",
                "- Multi-Selektion der Aggregation (avg, mean, std, ...)\n",
                "- Frequenzanalyse\n",
                "- Fourier-Transformation\n",
                "- Fenstergröße nach Frequenzbereichen\n",
                "\n",
                "### 3.1 Vorbereitung der Tainings- und Testdaten\n",
                "\n",
                "Multi-Selektion für:\n",
                "\n",
                "- Features\n",
                "- Betriebspunkte (RPM/FLOWRATE)\n",
                "- Klassifikationsarten (Szenario / Testdurchlauf)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "id": "103ea4fa",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bb1cee76de134e66aee2b8c30012752a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='Window size in ms: ', options=('100', '200', '300', '400', '500', '600', '700', '800', '…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3d879dc79e8b4966bd686e6c4dc25c63",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='Raw data type: ', options=('KIDAQ', 'VIB'), value='KIDAQ')"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "537bce3517744688a9fc11cb565adc09",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "SelectMultiple(description='Aggregations:', options=('std', 'range', 'iqr', 'mean_median'), value=())"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "\n",
                "WINDOW_SIZE_MS = [\"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\", \"800\",\"900\",\"1000\"]\n",
                "AGGREGATIONS = [\"std\", \"range\", \"iqr\", \"mean_median\"]\n",
                "\n",
                "win_sizes = widgets.Dropdown(\n",
                "    placeholder= \"Choose the window size in ms\",\n",
                "    options = WINDOW_SIZE_MS,\n",
                "    description = \"Window size in ms: \",\n",
                "    ensure_option=True,\n",
                "    disabled = False\n",
                ")\n",
                "display(win_sizes)\n",
                "\n",
                "raw_data_type = widgets.Dropdown(\n",
                "    placeholder= \"Choose the raw data type\",\n",
                "    options = RAW_DATA_TYPE,\n",
                "    description = \"Raw data type: \",\n",
                "    ensure_option=True,\n",
                "    disabled = False\n",
                ")\n",
                "display(raw_data_type)\n",
                "\n",
                "aggregations = widgets.SelectMultiple(\n",
                "    options = AGGREGATIONS,\n",
                "    description = \"Aggregations:\",\n",
                "    disabled = False\n",
                ")\n",
                "display(aggregations)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "38d30db2",
            "metadata": {},
            "outputs": [],
            "source": [
                "COLUMNS=[\n",
                "    \"p1\",\n",
                "    \"p2\",\n",
                "    \"a2\",\n",
                "    \"T2\",\n",
                "    \"T1\"\n",
                "]\n",
                "\n",
                "CWD = pl.Path.cwd()\n",
                "\n",
                "PATH_RAW_DATA = CWD / \"data\" / \"raw\"\n",
                "PATH_TO_SETUP = PATH_RAW_DATA / \"Setup-I\"\n",
                "\n",
                "\n",
                "kidaq_files = [file for file in PATH_TO_SETUP.glob(\"**/*.mf4\")]\n",
                "\n",
                "\n",
                "\n",
                "def process_file(file):\n",
                "    \n",
                "    error_type = file.parts[8]\n",
                "    rpm = file.parts[10].split(\"r\")[0]\n",
                "    rpm_percent = file.parts[11].split(\"m\")[1].split(\"%\")[0]\n",
                "    \n",
                "    mdf = asammdf.MDF(file)\n",
                "    df = mdf.to_dataframe()\n",
                "    df = df.reset_index()\n",
                "\n",
                "    df = df[COLUMNS]\n",
                "\n",
                "    df_features = None\n",
                "\n",
                "    windows = df.groupby(df.index // (int(win_sizes.value) * 20))\n",
                "\n",
                "    for _, window in windows:\n",
                "\n",
                "        features = {\n",
                "            \"Fehlertyp\": error_type, \n",
                "            \"rpm\": rpm, \n",
                "            \"rpm%\": rpm_percent\n",
                "            }\n",
                "\n",
                "        for agg in aggregations.value:\n",
                "            match agg:\n",
                "                case \"std\":\n",
                "                    features[\"p1_std\"] = window[\"p1\"].std()\n",
                "                    features[\"p2_std\"] = window[\"p2\"].std()\n",
                "                    features[\"a2_std\"] = window[\"a2\"].std()\n",
                "                    features[\"T2_std\"] = window[\"T2\"].std()\n",
                "                    features[\"T1_std\"] = window[\"T1\"].std()\n",
                "                case \"range\":\n",
                "                    features[\"p1_range\"] =  window[\"p1\"].max() - window[\"p1\"].min()\n",
                "                    features[\"p2_range\"] =  window[\"p2\"].max() - window[\"p2\"].min()\n",
                "                    features[\"a2_range\"] =  window[\"a2\"].max() - window[\"a2\"].min()\n",
                "                    features[\"T2_range\"] =  window[\"T2\"].max() - window[\"T2\"].min()\n",
                "                    features[\"T1_range\"] =  window[\"T1\"].max() - window[\"T1\"].min()\n",
                "                case \"iqr\":\n",
                "                    features[\"p1_iqr\"] = window[\"p1\"].quantile(0.75) - window[\"p1\"].quantile(0.25)\n",
                "                    features[\"p2_iqr\"] = window[\"p2\"].quantile(0.75) - window[\"p2\"].quantile(0.25)\n",
                "                    features[\"a2_iqr\"] = window[\"a2\"].quantile(0.75) - window[\"a2\"].quantile(0.25)\n",
                "                    features[\"T2_iqr\"] = window[\"T2\"].quantile(0.75) - window[\"T2\"].quantile(0.25)\n",
                "                    features[\"T1_iqr\"] = window[\"T1\"].quantile(0.75) - window[\"T1\"].quantile(0.25)\n",
                "                case \"median\":\n",
                "                    features[\"p1_median\"] =  window[\"p1\"].median()\n",
                "                    features[\"p2_median\"] =  window[\"p2\"].median()\n",
                "                    features[\"a2_median\"] =  window[\"a2\"].median()\n",
                "                    features[\"T2_median\"] =  window[\"T2\"].median()\n",
                "                    features[\"T1_median\"] =  window[\"T1\"].median()\n",
                "                case _:\n",
                "                    print(\"No aggregation selected\")\n",
                "\n",
                "        if df_features is None:\n",
                "            df_features = pd.DataFrame(features, index=[0])    \n",
                "        else:\n",
                "            df_features = pd.concat([df_features, pd.DataFrame(features, index=[0])])\n",
                "\n",
                "    return df_features\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "877111cd",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9526034292ea4d8685b1b828e3a0807c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/20 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "\n",
                "RESULT_FILE = CWD / \"data\" / f\"{raw_data_type.value}_features.csv\"\n",
                "\n",
                "for file in tqdm(kidaq_files):\n",
                "    features = process_file(file)\n",
                "\n",
                "    if features is not None:\n",
                "        if not pl.Path(RESULT_FILE).exists():\n",
                "            features.to_csv(RESULT_FILE, index=False)\n",
                "        else:\n",
                "            features.to_csv(RESULT_FILE, mode=\"a\", header=False, index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b8ed0170-f3d5-4287-8dd8-7439080d27af",
            "metadata": {},
            "source": [
                "## 4. Deskriptive/Explorative Datenanalyse [Philipp]\n",
                "\n",
                "- Plots\n",
                "- Beschreibung der Plots\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4b92fefe-672c-4bba-97c1-f78747ff1dc1",
            "metadata": {},
            "source": [
                "## 5. Machine Learning [Kevin]\n",
                "\n",
                "Multi-Selektion für:\n",
                "\n",
                "- Auswahl der Featuredateien (Train/Testdaten)\n",
                "- Auswahl des Learners\n",
                "- Konfiguration der Hyperparameter\n",
                "- Live-Validation des Models mit vorausgewählten Testdaten (Random-Search, ...)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "id": "d8da6989",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a120f41efd1c41fd834ffa1a46912c52",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='training features', options=('KIDAQ_features.csv',), value=None)"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "687ffb7655db4012a23aa00d253a39d1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='test features', options=('KIDAQ_features.csv',), value=None)"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# SELECT TRAINING AND TEST DATA\n",
                "featureDataDir = list(filter(lambda x: os.path.isfile(os.path.join(PATH_FEATURE_DATA, x)) and DEFAULT_RAW_DATA_TYPE in x.upper(), os.listdir(PATH_FEATURE_DATA)))\n",
                "\n",
                "modelDropdown = widgets.Dropdown(description=\"training features\")\n",
                "modelDropdown.options = featureDataDir\n",
                "selectedModelFile = None\n",
                "def onTrainigFileChange(change):\n",
                "    global selectedModelFile\n",
                "    selectedModelFile = change['new']\n",
                "modelDropdown.observe(onTrainigFileChange, names='value')\n",
                "display(modelDropdown)\n",
                "\n",
                "testFileDropdown = widgets.Dropdown(description=\"test features\")\n",
                "testFileDropdown.options = featureDataDir\n",
                "selectedTestFile = None\n",
                "def onTestFileChange(change):\n",
                "    global selectedTestFile\n",
                "    selectedTestFile = change['new']\n",
                "testFileDropdown.observe(onTestFileChange, names='value')\n",
                "display(testFileDropdown)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "id": "5e8f18d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# SET ML CONFIG\n",
                "FEATURE_TRAIN_FILE = PATH_FEATURE_DATA + selectedModelFile\n",
                "FEATURE_TEST_FILE = PATH_FEATURE_DATA + selectedTestFile\n",
                "\n",
                "DEFAULT_OPERATING_POINTS = OPERATING_POINT_FREQ + OPERATING_POINT_FLOW_RATE\n",
                "\n",
                "\n",
                "# DNN\n",
                "DNN_EXPLORATION_TARGET_VAL_ACCURACY = 0.9\n",
                "DNN_EXPLORATION_MAX_ITER = 1\n",
                "DNN_EXPLORATION_HIDDEN_LAYERS_MIN = 2\n",
                "DNN_EXPLORATION_HIDDEN_LAYERS_MAX = 4\n",
                "DNN_EXPLORATION_NEURONS_MIN = 8\n",
                "DNN_EXPLORATION_NEURONS_MAX = 64\n",
                "\n",
                "\n",
                "DNN_EARLY_STOPPING_PATIENCE = 50\n",
                "DNN_VERBOSE = 0\n",
                "DNN_EPOCHS = 100\n",
                "DNN_BATCH_SIZE = 32\n",
                "DNN_BATCH_NORMALIZATION = True\n",
                "\n",
                "\n",
                "# DT\n",
                "DT_MAX_DEPTH = 6\n",
                "DT_NUM_ESTIMATORS = 100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "id": "51491a91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOAD DATA\n",
                "train_data = read_csv(FEATURE_TRAIN_FILE, header=None, delimiter=\";\").values\n",
                "test_data = read_csv(FEATURE_TEST_FILE, header=None, delimiter=\";\").values\n",
                "\n",
                "train_x, train_y = train_data[:, 2:].astype('float32'), train_data[:, 1:2]\n",
                "test_x, test_y = test_data[:, 2:].astype('float32'), test_data[:, 1:2]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "id": "d6d7b343",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'sklearn'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train Decision Tree\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBClassifier\n",
                        "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
                    ]
                }
            ],
            "source": [
                "# Train Decision Tree\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "\n",
                "labelEncoder = LabelEncoder()\n",
                "labelEncoder = labelEncoder.fit(np.ravel(train_y))\n",
                "label_encoded_train_y = labelEncoder.transform(np.ravel(train_y))\n",
                "label_encoded_test_y = labelEncoder.transform(np.ravel(test_y))\n",
                "\n",
                "\n",
                "xgb = XGBClassifier(\n",
                "    tree_method=\"hist\",\n",
                "    enable_categorical=True,\n",
                "    max_depth=DT_MAX_DEPTH,\n",
                "    n_estimators=DT_NUM_ESTIMATORS,\n",
                ")\n",
                "# fit model\n",
                "xgb.fit(train_x, label_encoded_train_y, eval_set=[(test_x, label_encoded_test_y)])\n",
                "\n",
                "\n",
                "preds = xgb.predict(test_x)\n",
                "accuracy = accuracy_score(label_encoded_test_y, preds)\n",
                "\n",
                "XGBClassifier.save_model(xgb, PATH_MODEL+\"dt.\"+str(round(time.time())))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "id": "f987c57a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "132/132 [==============================] - 1s 3ms/step - loss: 0.9004 - accuracy: 0.6606 - val_loss: 1.0207 - val_accuracy: 0.5953\n",
                        "Epoch 2/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7988 - val_loss: 1.3973 - val_accuracy: 0.5450\n",
                        "Epoch 3/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8342 - val_loss: 2.0212 - val_accuracy: 0.5111\n",
                        "Epoch 4/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8565 - val_loss: 2.3167 - val_accuracy: 0.5017\n",
                        "Epoch 5/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8765 - val_loss: 2.3918 - val_accuracy: 0.5269\n",
                        "Epoch 6/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8843 - val_loss: 2.7863 - val_accuracy: 0.5153\n",
                        "Epoch 7/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9014 - val_loss: 2.8136 - val_accuracy: 0.5164\n",
                        "Epoch 8/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9143 - val_loss: 2.9690 - val_accuracy: 0.5082\n",
                        "Epoch 9/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9216 - val_loss: 2.9043 - val_accuracy: 0.5785\n",
                        "Epoch 10/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9366 - val_loss: 3.1016 - val_accuracy: 0.5118\n",
                        "Epoch 11/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9287 - val_loss: 3.1998 - val_accuracy: 0.5218\n",
                        "Epoch 12/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9394 - val_loss: 3.0162 - val_accuracy: 0.5651\n",
                        "Epoch 13/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9385 - val_loss: 2.9197 - val_accuracy: 0.5960\n",
                        "Epoch 14/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9444 - val_loss: 3.2499 - val_accuracy: 0.5471\n",
                        "Epoch 15/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9456 - val_loss: 3.5795 - val_accuracy: 0.5412\n",
                        "Epoch 16/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9504 - val_loss: 3.6302 - val_accuracy: 0.5213\n",
                        "Epoch 17/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9449 - val_loss: 3.4481 - val_accuracy: 0.5181\n",
                        "Epoch 18/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9382 - val_loss: 3.8803 - val_accuracy: 0.5318\n",
                        "Epoch 19/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9468 - val_loss: 4.0392 - val_accuracy: 0.5053\n",
                        "Epoch 20/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9473 - val_loss: 4.2577 - val_accuracy: 0.5079\n",
                        "Epoch 21/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9582 - val_loss: 4.1900 - val_accuracy: 0.5011\n",
                        "Epoch 22/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9570 - val_loss: 4.4731 - val_accuracy: 0.5033\n",
                        "Epoch 23/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9632 - val_loss: 4.3101 - val_accuracy: 0.5038\n",
                        "Epoch 24/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9594 - val_loss: 4.3684 - val_accuracy: 0.5014\n",
                        "Epoch 25/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9625 - val_loss: 4.2405 - val_accuracy: 0.5021\n",
                        "Epoch 26/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9565 - val_loss: 4.2689 - val_accuracy: 0.5000\n",
                        "Epoch 27/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 4.3068 - val_accuracy: 0.5003\n",
                        "Epoch 28/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9589 - val_loss: 4.4923 - val_accuracy: 0.5001\n",
                        "Epoch 29/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9575 - val_loss: 4.5082 - val_accuracy: 0.5001\n",
                        "Epoch 30/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9589 - val_loss: 4.3810 - val_accuracy: 0.5004\n",
                        "Epoch 31/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9634 - val_loss: 4.6092 - val_accuracy: 0.5000\n",
                        "Epoch 32/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9610 - val_loss: 4.5529 - val_accuracy: 0.5000\n",
                        "Epoch 33/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9653 - val_loss: 4.9003 - val_accuracy: 0.5000\n",
                        "Epoch 34/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9622 - val_loss: 4.7165 - val_accuracy: 0.5000\n",
                        "Epoch 35/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9608 - val_loss: 4.6681 - val_accuracy: 0.5003\n",
                        "Epoch 36/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9670 - val_loss: 4.8815 - val_accuracy: 0.5003\n",
                        "Epoch 37/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9580 - val_loss: 4.8013 - val_accuracy: 0.5000\n",
                        "Epoch 38/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9675 - val_loss: 4.5455 - val_accuracy: 0.5001\n",
                        "Epoch 39/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9651 - val_loss: 4.2004 - val_accuracy: 0.5001\n",
                        "Epoch 40/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9660 - val_loss: 4.2737 - val_accuracy: 0.5000\n",
                        "Epoch 41/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9641 - val_loss: 4.6304 - val_accuracy: 0.5000\n",
                        "Epoch 42/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9701 - val_loss: 4.1757 - val_accuracy: 0.5001\n",
                        "Epoch 43/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9696 - val_loss: 4.4978 - val_accuracy: 0.5054\n",
                        "Epoch 44/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9691 - val_loss: 4.1302 - val_accuracy: 0.5000\n",
                        "Epoch 45/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9701 - val_loss: 4.0377 - val_accuracy: 0.5017\n",
                        "Epoch 46/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9656 - val_loss: 3.8071 - val_accuracy: 0.5006\n",
                        "Epoch 47/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9660 - val_loss: 4.2440 - val_accuracy: 0.5003\n",
                        "Epoch 48/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9743 - val_loss: 4.5723 - val_accuracy: 0.5003\n",
                        "Epoch 49/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9651 - val_loss: 4.2878 - val_accuracy: 0.5083\n",
                        "Epoch 50/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 4.3093 - val_accuracy: 0.5018\n",
                        "Epoch 51/100\n",
                        "132/132 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9736 - val_loss: 3.7391 - val_accuracy: 0.5038\n",
                        "132/132 [==============================] - 0s 729us/step - loss: 0.9120 - accuracy: 0.6190\n",
                        "225/225 [==============================] - 0s 710us/step - loss: 1.0207 - accuracy: 0.5953\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: ./models/dnn.1685239363\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: ./models/dnn.1685239363\\assets\n"
                    ]
                }
            ],
            "source": [
                "# Train Neural Network\n",
                "import json\n",
                "import random\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from tensorflow.keras import Sequential\n",
                "from tensorflow.keras.layers import Dense, InputLayer, BatchNormalization\n",
                "from tensorflow.keras.callbacks import EarlyStopping\n",
                "\n",
                "onehotencoder = OneHotEncoder()\n",
                "onehotencoder = onehotencoder.fit(train_y)\n",
                "onehot_encoded_train_y = onehotencoder.transform(train_y).toarray()\n",
                "onehot_encoded_test_y = onehotencoder.transform(test_y).toarray()\n",
                "\n",
                "exploration_results = []\n",
                "\n",
                "\n",
                "n_features = train_x.shape[1]\n",
                "categories = len(onehot_encoded_train_y[0])\n",
                "\n",
                "test_acc = 0.0\n",
                "model = Sequential()\n",
                "interation = 0\n",
                "while (\n",
                "    test_acc < DNN_EXPLORATION_TARGET_VAL_ACCURACY\n",
                "    and interation < DNN_EXPLORATION_MAX_ITER\n",
                "):\n",
                "    model = Sequential()\n",
                "    model.add(InputLayer(input_shape=(n_features,)))\n",
                "    model.add(BatchNormalization())\n",
                "    dense_count = random.randint(\n",
                "        DNN_EXPLORATION_HIDDEN_LAYERS_MIN, DNN_EXPLORATION_HIDDEN_LAYERS_MAX\n",
                "    )\n",
                "    dense_neurons = []\n",
                "    for i in range(0, dense_count):\n",
                "        neurons = random.randint(\n",
                "            DNN_EXPLORATION_NEURONS_MIN, DNN_EXPLORATION_NEURONS_MAX\n",
                "        )\n",
                "        dense_neurons.append(neurons)\n",
                "        model.add(Dense(neurons, activation=\"tanh\"))\n",
                "        model.add(BatchNormalization())\n",
                "    model.add(Dense(categories, activation=\"sigmoid\"))\n",
                "    model.compile(\n",
                "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
                "    )\n",
                "    model.fit(\n",
                "        train_x,\n",
                "        onehot_encoded_train_y,\n",
                "        epochs=DNN_EPOCHS,\n",
                "        batch_size=DNN_BATCH_SIZE,\n",
                "        verbose=1,\n",
                "        validation_data=(test_x, onehot_encoded_test_y),\n",
                "        callbacks=[\n",
                "            EarlyStopping(\n",
                "                monitor=\"val_loss\",\n",
                "                patience=DNN_EARLY_STOPPING_PATIENCE,\n",
                "                restore_best_weights=True,\n",
                "            )\n",
                "        ],\n",
                "    )\n",
                "\n",
                "    train_loss, train_acc = model.evaluate(train_x, onehot_encoded_train_y)\n",
                "    test_loss, test_acc = model.evaluate(test_x, onehot_encoded_test_y)\n",
                "\n",
                "    exploration_results.append(\n",
                "        {\n",
                "            \"dense_count\": dense_count,\n",
                "            \"dense_neurons\": dense_neurons,\n",
                "            \"train_loss\": train_loss,\n",
                "            \"train_acc\": train_acc,\n",
                "            \"test_loss\": test_loss,\n",
                "            \"test_acc\": test_acc,\n",
                "        }\n",
                "    )\n",
                "    interation += 1\n",
                "\n",
                "modelName = \"dnn.\" + str(round(time.time()))\n",
                "model.save(PATH_MODEL + modelName)\n",
                "\n",
                "with open(PATH_EXPLORATION_DATA + modelName + \".exploration_results.json\", \"w\") as f:\n",
                "    json.dump(exploration_results, f, indent=4)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "615dfc90-2798-42fe-8001-7be9ea78aa35",
            "metadata": {},
            "source": [
                "## 6. Modelanalyse des Learners [Kevin]\n",
                "\n",
                "- Vorherige Auswahl eines Learners\n",
                "- Feature Importance\n",
                "- Korrelationsmatrix\n",
                "- Konfusionsmatrix\n",
                "- Post-Validation des Models mit auswählbaren Daten\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "id": "72ea0d36",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6f4e88c5d25e4ec887f6417738be3b27",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='model', options=('dnn.1685239363', 'dt.1685239368'), value=None)"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7248a6ae46b3438587107fcfb1a25b12",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='test data', options=('vib.setup1.csv', 'vib.setup2.csv'), value=None)"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# SELECT LEARNER AND TEST DATA\n",
                "featureDataDir = list(filter(lambda x: os.path.isfile(os.path.join(PATH_FEATURE_DATA, x)) and DEFAULT_RAW_DATA_TYPE in x.upper(), os.listdir(PATH_FEATURE_DATA)))\n",
                "modelDir = os.listdir(PATH_MODEL)\n",
                "\n",
                "modelDropdown = widgets.Dropdown(description=\"model\")\n",
                "modelDropdown.options = modelDir\n",
                "selectedModelFile = None\n",
                "def onTrainigFileChange(change):\n",
                "    global selectedModelFile\n",
                "    selectedModelFile = change['new']\n",
                "modelDropdown.observe(onTrainigFileChange, names='value')\n",
                "display(modelDropdown)\n",
                "\n",
                "testFileDropdown = widgets.Dropdown(description=\"test data\")\n",
                "testFileDropdown.options = featureDataDir\n",
                "selectedTestFile = None\n",
                "def onTestFileChange(change):\n",
                "    global selectedTestFile\n",
                "    selectedTestFile = change['new']\n",
                "testFileDropdown.observe(onTestFileChange, names='value')\n",
                "display(testFileDropdown)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e3540ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ANALYZE MODEL\n",
                "from matplotlib import pyplot\n",
                "from tensorflow import math as tfmath\n",
                "import tensorflow_probability as tfp\n",
                "import eli5\n",
                "from eli5.sklearn import PermutationImportance\n",
                "\n",
                "conf_matrix = tfmath.confusion_matrix(np.argmax(y_test, axis=1), np.argmax(result, axis=1))\n",
                "pyplot.matshow(conf_matrix, 1)\n",
                "for (x, y), value in np.ndenumerate(conf_matrix):\n",
                "    pyplot.text(y, x, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
                "pyplot.show()\n",
                "\n",
                "\n",
                "print('Test Accuracy: %.3f' % test_acc)\n",
                "\n",
                "\n",
                "corr_matrix = tfp.stats.correlation(X_test)\n",
                "pyplot.matshow(corr_matrix)\n",
                "pyplot.show()\n",
                "\n",
                "perm = PermutationImportance(model, scoring=\"neg_mean_squared_error\", random_state=1).fit(X_test, y_test)\n",
                "print(eli5.format_as_text(eli5.explain_weights(perm, feature_names=feature_names)))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "390a4a00-cdc0-4fae-bd1f-e92cd875dec1",
            "metadata": {},
            "source": [
                "## 7. Statische Interpretation des Resultats\n",
                "\n",
                "- Welches Ergebnis haben wir erzielt und wie kann man es anwenden?\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
