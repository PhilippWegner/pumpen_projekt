{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d5a94bd2-a922-4b01-a9b9-7658e41f6036",
            "metadata": {},
            "source": [
                "# Aufbau der Notebooks [Philipp]\n",
                "\n",
                "- Multivalue bei Notebooks angucken\n",
                "- Wie installiere ich den \"scheiß\"\n",
                "- Widgets: https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "d3394772",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "ldf is not supported\n",
                        "xls is not supported\n",
                        "xlsx is not supported\n",
                        "yaml is not supported\n"
                    ]
                }
            ],
            "source": [
                "from enum import Enum\n",
                "import ipywidgets as widgets\n",
                "from pandas import read_csv\n",
                "import pandas as pd\n",
                "import asammdf\n",
                "from IPython.display import display\n",
                "import os\n",
                "import numpy as np\n",
                "import time\n",
                "import pathlib as pl"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d08d88a7-0fc1-4c7a-91f7-df5aa0a4f9a2",
            "metadata": {},
            "source": [
                "## 1. Aufgabe und Daten erklären/beschreiben [Philipp]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "268ea6b8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c778fb6ab59141278193e5eb98626404",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "TagsInput(value=['TEST_NAME', 'TEST_TYPE', 'RPM', 'FLOW_RATE', 'P1', 'P2'], allow_duplicates=False, allowed_ta…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Globals\n",
                "\n",
                "PATH_RAW_DATA = \"./data/raw/\"\n",
                "PATH_FEATURE_DATA = \"./data/\"\n",
                "PATH_EXPLORATION_DATA = \"./exploration/\"\n",
                "PATH_MODEL = \"./models/\"\n",
                "DATA_SOURCE_KIDAQ = [\"TEST_NAME\", \"TEST_TYPE\", \"RPM\", \"FLOW_RATE\", \"P1\", \"P2\"]\n",
                "RAW_DATA_TYPE = [\"KIDAQ\", \"VIB\"]\n",
                "\n",
                "DATA_SOURCE_VID = [\n",
                "    \"TEST_NAME\",\n",
                "    \"TEST_TYPE\",\n",
                "    \"RPM\",\n",
                "    \"FLOW_RATE\",\n",
                "    \"S1\",\n",
                "    \"S2\",\n",
                "    \"S3\",\n",
                "    \"S4\",\n",
                "    \"S5\",\n",
                "    \"S6\",\n",
                "    \"S7\",\n",
                "    \"S8\",\n",
                "]\n",
                "FEATURE = [\n",
                "    \"STD\",\n",
                "    \"RANGE\",\n",
                "    \"IQR\",\n",
                "    \"MEAN_MEDIAN\",\n",
                "    \"FFT\",\n",
                "]\n",
                "OPERATING_POINT_FREQ = [725, 1450, 2175, 2900]\n",
                "OPERATING_POINT_FLOW_RATE = [0, 25, 50, 75, 100]\n",
                "\n",
                "LEARNER = Enum(\"LEARNER\", [\"DNN\", \"DT\"])\n",
                "\n",
                "DEFAULT_LEARNER = LEARNER.DNN\n",
                "DEFAULT_RAW_DATA_TYPE = RAW_DATA_TYPE[0]\n",
                "DEFAULT_RAW_DATA = DATA_SOURCE_KIDAQ\n",
                "\n",
                "DEFAULT_CLASS_LABEL = \"TEST_TYPE\"\n",
                "\n",
                "tags = widgets.TagsInput(\n",
                "    value=DEFAULT_RAW_DATA, allowed_tags=DEFAULT_RAW_DATA, allow_duplicates=False\n",
                ")\n",
                "display(tags)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6efc6220-a14b-4ff0-b0d8-66ba17569050",
            "metadata": {},
            "source": [
                "## 3. Preprocessing [Valerij]\n",
                "\n",
                "Aufgeteilt nach KIDAQ und VIB (separat um es einfach zu halten)\n",
                "\n",
                "- Auswahl der Fenstergröße in Millisekunden\n",
                "- Auswahl der Abtastrate\n",
                "- Multi-Selektion der Aggregation (avg, mean, std, ...)\n",
                "- Frequenzanalyse\n",
                "- Fourier-Transformation\n",
                "- Fenstergröße nach Frequenzbereichen\n",
                "\n",
                "### 3.1 Vorbereitung der Tainings- und Testdaten\n",
                "\n",
                "Multi-Selektion für:\n",
                "\n",
                "- Features\n",
                "- Betriebspunkte (RPM/FLOWRATE)\n",
                "- Klassifikationsarten (Szenario / Testdurchlauf)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1eaf4db6",
            "metadata": {},
            "source": [
                "# Vorauswahl der Feature Einstellungen und Auswahl der Daten"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "103ea4fa",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6482394aef5246aeb93b5ed4dc51b418",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='Window size in ms: ', options=('100', '200', '300', '400', '500', '600', '700', '800', '…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6fec0f8aafd9407987719951f99a03a7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='Raw data type: ', options=('KIDAQ', 'VIB'), value='KIDAQ')"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "321504028d7741c0b8ca88b4e28e7efa",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='Raw data folder: ', options=('Setup-I',), value='Setup-I')"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "WINDOW_SIZE_MS = [\"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\", \"800\",\"900\",\"1000\"]\n",
                "AGGREGATIONS = [\"std\", \"range\", \"iqr\", \"median\"]\n",
                "\n",
                "win_sizes = widgets.Dropdown(\n",
                "    placeholder= \"Choose the window size in ms\",\n",
                "    options = WINDOW_SIZE_MS,\n",
                "    description = \"Window size in ms: \",\n",
                "    ensure_option=True,\n",
                "    disabled = False\n",
                ")\n",
                "display(win_sizes)\n",
                "\n",
                "raw_data_type = widgets.Dropdown(\n",
                "    placeholder= \"Choose the raw data type\",\n",
                "    options = RAW_DATA_TYPE,\n",
                "    description = \"Raw data type: \",\n",
                "    ensure_option=True,\n",
                "    disabled = False\n",
                ")\n",
                "display(raw_data_type)\n",
                "\n",
                "# list all available directories in data/raw with max depth of 1\n",
                "raw_data_folders = [f.name for f in os.scandir(PATH_RAW_DATA) if f.is_dir()]\n",
                "raw_data_folder = widgets.Dropdown(\n",
                "    placeholder= \"Choose the raw data folder\",\n",
                "    options = raw_data_folders,\n",
                "    description = \"Raw data folder: \",\n",
                "    ensure_option=True,\n",
                "    disabled = False\n",
                ")\n",
                "display(raw_data_folder)\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "92309790",
            "metadata": {},
            "source": [
                "## Definition der Funktionen zum Preprocessing der verschiedenen Datentypen"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "38d30db2",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from tqdm.notebook import tqdm\n",
                "COLUMNS_KiDAQ = [\n",
                "    \"p1\",\n",
                "    \"p2\",\n",
                "    \"a2\",\n",
                "    \"T2\",\n",
                "    \"T1\"\n",
                "]\n",
                "\n",
                "\n",
                "CWD = pl.Path.cwd()\n",
                "\n",
                "PATH_RAW_DATA = CWD / \"data\" / \"raw\"\n",
                "PATH_TO_SETUP = PATH_RAW_DATA / raw_data_folder.value \n",
                "\n",
                "\n",
                "if raw_data_type.value == \"KIDAQ\":\n",
                "    raw_files = [file for file in PATH_TO_SETUP.glob(\"**/*.mf4\") if \"KiDAQ\" in file.parts]    \n",
                "elif raw_data_type.value == \"VIB\":\n",
                "    raw_files = [file for file in PATH_TO_SETUP.glob(\"**/*.csv\") if \"Rohdaten CSV\" in file.parts]\n",
                "def process_vib(file):\n",
                "    # error_type is the first folder name after the setup folder\n",
                "    error_type_with_number = file.parts[8]\n",
                "    error_type = error_type_with_number.split(\" \")[0]\n",
                "    rpm = file.parts[10].split(\"r\")[0]\n",
                "    rpm_percent = file.parts[11].split(\"%\")[0]\n",
                "    sensor = file.parts[-1].split(\" \")[0]\n",
                "    version = file.parts[12] if file.parts[12] != None else '0'\n",
                "\n",
                "    df = read_csv(file, skiprows=2, encoding=\"ISO-8859-1\", sep=\";\")\n",
                "\n",
                "    df[\"Timestamp [ns]\"] = pd.to_datetime(df[\"Timestamp [ns]\"], unit=\"ns\")\n",
                "    df = df.set_index(\"Timestamp [ns]\")\n",
                "    resampled = df.resample(\"1s\")\n",
                "\n",
                "    df_mean = resampled.mean()\n",
                "    df_mean = df_mean.rename(columns={\"Value\": f\"{sensor}_mean\"})\n",
                "    df_range = resampled.max() - resampled.min()\n",
                "    df_range = df_range.rename(columns={\"Value\": f\"{sensor}_range\"})\n",
                "    df_std = resampled.std()\n",
                "    df_std = df_std.rename(columns={\"Value\": f\"{sensor}_std\"})\n",
                "    df_iqr = resampled.quantile(0.75) - resampled.quantile(0.25)\n",
                "    df_iqr = df_iqr.rename(columns={\"Value\": f\"{sensor}_iqr\"})\n",
                "    df_mean_median = resampled.mean() - resampled.median()\n",
                "    df_mean_median = df_mean_median.rename(columns={\"Value\": f\"{sensor}_mean_median\"})\n",
                "\n",
                "    df = pd.concat([df_mean, df_range, df_std, df_iqr, df_mean_median], axis=1)\n",
                "    df[\"Fehlertyp\"] = error_type_with_number\n",
                "    df[\"Fehlertyp_allgemein\"] = error_type\n",
                "    df[\"rpm\"] = rpm\n",
                "    df[\"rpm%\"] = rpm_percent\n",
                "    df[\"version\"] = version\n",
                "    df = df.reset_index()\n",
                "    df = df.drop(columns=[\"Timestamp [ns]\"])\n",
                "    df[\"ID\"] = df.index\n",
                "    df = df.melt(\n",
                "        id_vars=[\"ID\", \"Fehlertyp\", \"Fehlertyp_allgemein\", \"rpm\", \"rpm%\", \"version\"],\n",
                "        var_name=\"Aggregation\",\n",
                "        value_name=\"Value\",\n",
                "    )\n",
                "\n",
                "    return df \n",
                "\n",
                "    \n",
                "\n",
                "\n",
                "def process_kidaq(file):\n",
                "    \n",
                "    error_type_with_number = file.parts[8]\n",
                "    error_type = error_type_with_number.split(\" \")[0]\n",
                "    rpm = file.parts[10].split(\"r\")[0]\n",
                "    rpm_percent = file.parts[11].split(\"m\")[1].split(\"%\")[0]\n",
                "    \n",
                "    mdf = asammdf.MDF(file)\n",
                "    df = mdf.to_dataframe()\n",
                "    df = df.reset_index()\n",
                "\n",
                "    df = df[COLUMNS_KiDAQ]\n",
                "\n",
                "    df_features = None\n",
                "\n",
                "    windows = df.groupby(df.index // (int(win_sizes.value) * 20))\n",
                "\n",
                "    for _, window in windows:\n",
                "\n",
                "        features = {\n",
                "            \"Fehlertyp\": error_type_with_number, \n",
                "            \"Fehlertyp_allgemein\": error_type,\n",
                "            \"rpm\": rpm, \n",
                "            \"rpm%\": rpm_percent\n",
                "            }\n",
                "\n",
                "        features[\"p1_std\"] = window[\"p1\"].std()\n",
                "        features[\"p2_std\"] = window[\"p2\"].std()\n",
                "        features[\"a2_std\"] = window[\"a2\"].std()\n",
                "        features[\"T2_std\"] = window[\"T2\"].std()\n",
                "        features[\"T1_std\"] = window[\"T1\"].std()\n",
                "        \n",
                "        features[\"p1_range\"] =  window[\"p1\"].max() - window[\"p1\"].min()\n",
                "        features[\"p2_range\"] =  window[\"p2\"].max() - window[\"p2\"].min()\n",
                "        features[\"a2_range\"] =  window[\"a2\"].max() - window[\"a2\"].min()\n",
                "        features[\"T2_range\"] =  window[\"T2\"].max() - window[\"T2\"].min()\n",
                "        features[\"T1_range\"] =  window[\"T1\"].max() - window[\"T1\"].min()\n",
                "        \n",
                "        features[\"p1_iqr\"] = window[\"p1\"].quantile(0.75) - window[\"p1\"].quantile(0.25)\n",
                "        features[\"p2_iqr\"] = window[\"p2\"].quantile(0.75) - window[\"p2\"].quantile(0.25)\n",
                "        features[\"a2_iqr\"] = window[\"a2\"].quantile(0.75) - window[\"a2\"].quantile(0.25)\n",
                "        features[\"T2_iqr\"] = window[\"T2\"].quantile(0.75) - window[\"T2\"].quantile(0.25)\n",
                "        features[\"T1_iqr\"] = window[\"T1\"].quantile(0.75) - window[\"T1\"].quantile(0.25)\n",
                "        \n",
                "        features[\"p1_mean_median\"] = window[\"p1\"].mean() - window[\"p1\"].median()\n",
                "        features[\"p2_mean_median\"] = window[\"p2\"].mean() - window[\"p2\"].median()\n",
                "        features[\"a2_mean_median\"] = window[\"a2\"].mean() - window[\"a2\"].median()\n",
                "        features[\"T2_mean_median\"] = window[\"T2\"].mean() - window[\"T2\"].median()\n",
                "        features[\"T1_mean_median\"] = window[\"T1\"].mean() - window[\"T1\"].median()\n",
                "\n",
                "        if df_features is None:\n",
                "            df_features = pd.DataFrame(features, index=[0])    \n",
                "        else:\n",
                "            df_features = pd.concat([df_features, pd.DataFrame(features, index=[0])])\n",
                "\n",
                "    return df_features\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "c14cf0f1",
            "metadata": {},
            "source": [
                "# Funktionem zum Preprocessing der Daten in den Frequenbereich und Generierung der Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "85e48db0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d631167a343c441d9787020420a00b07",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/20 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "timestamps\n",
                        "0 days 00:00:00    [[(42.29611140023917+0j), (-15.242247319128994...\n",
                        "0 days 00:00:01    [[(42.33119121013442+0j), (-15.248076272738823...\n",
                        "0 days 00:00:02    [[(42.856845155358315+0j), (-15.2365759376517+...\n",
                        "0 days 00:00:03    [[(42.365684810094535+0j), (-15.27886313085978...\n",
                        "0 days 00:00:04    [[(41.86934561282396+0j), (-15.22598530448626+...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(44.34265058208257+0j), (-15.830617847444534...\n",
                        "0 days 00:11:56    [[(44.22988194972277+0j), (-15.810493617696508...\n",
                        "0 days 00:11:57    [[(43.853430634364486+0j), (-15.87418575277656...\n",
                        "0 days 00:11:58    [[(44.63987521547824+0j), (-15.824939200804184...\n",
                        "0 days 00:11:59    [[(43.937125166878104+0j), (-15.84414651064455...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(39.49875782150775+0j), (-14.079091977710231...\n",
                        "0 days 00:00:01    [[(39.515013008378446+0j), (-14.10634013549823...\n",
                        "0 days 00:00:02    [[(39.53751224279404+0j), (-14.06500340538035+...\n",
                        "0 days 00:00:03    [[(39.29609020520002+0j), (-14.079175632664741...\n",
                        "0 days 00:00:04    [[(39.12386268004775+0j), (-14.037619526458606...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(40.14152138493955+0j), (-13.933620828860903...\n",
                        "0 days 00:11:56    [[(38.86608167272061+0j), (-13.921131927310618...\n",
                        "0 days 00:11:57    [[(40.09013059642166+0j), (-13.953586275601266...\n",
                        "0 days 00:11:58    [[(39.36083089932799+0j), (-13.96459421987758+...\n",
                        "0 days 00:11:59    [[(39.941296350210905+0j), (-13.90563731674240...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(42.24878437630832+0j), (-15.029701078804889...\n",
                        "0 days 00:00:01    [[(42.50296742096543+0j), (-15.055907367882345...\n",
                        "0 days 00:00:02    [[(41.61920754943276+0j), (-15.011134299403013...\n",
                        "0 days 00:00:03    [[(41.31010824255645+0j), (-15.030103621642105...\n",
                        "0 days 00:00:04    [[(41.56421692762524+0j), (-15.00712380024054+...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(41.12025790498592+0j), (-15.11524395053514+...\n",
                        "0 days 00:11:56    [[(41.35325281089172+0j), (-15.103193442817442...\n",
                        "0 days 00:11:57    [[(41.65403599385172+0j), (-15.101893515606722...\n",
                        "0 days 00:11:58    [[(41.56416081171483+0j), (-15.119843207446424...\n",
                        "0 days 00:11:59    [[(41.752979814540595+0j), (-15.11105185599120...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(40.66692961752415+0j), (-14.765711573049787...\n",
                        "0 days 00:00:01    [[(40.950500601902604+0j), (-14.77220080688744...\n",
                        "0 days 00:00:02    [[(40.12573728244752+0j), (-14.73191899486742+...\n",
                        "0 days 00:00:03    [[(41.11824378743768+0j), (-14.785347691980109...\n",
                        "0 days 00:00:04    [[(40.456433676183224+0j), (-14.77418520367619...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(40.29976413492113+0j), (-14.839855876507317...\n",
                        "0 days 00:11:56    [[(40.480729911476374+0j), (-14.82990581436709...\n",
                        "0 days 00:11:57    [[(40.50096334796399+0j), (-14.855070755752632...\n",
                        "0 days 00:11:58    [[(40.92208406981081+0j), (-14.850200553365656...\n",
                        "0 days 00:11:59    [[(40.72997786011547+0j), (-14.835959475752272...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(38.87075341772288+0j), (-14.317506106489507...\n",
                        "0 days 00:00:01    [[(38.98717846162617+0j), (-14.322617273873558...\n",
                        "0 days 00:00:02    [[(38.972742405720055+0j), (-14.30511276475429...\n",
                        "0 days 00:00:03    [[(39.28812141343951+0j), (-14.338202690176942...\n",
                        "0 days 00:00:04    [[(39.56415448337793+0j), (-14.315056184955782...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(40.84363423008472+0j), (-14.489165820592593...\n",
                        "0 days 00:11:56    [[(40.852511171251535+0j), (-14.48859858030076...\n",
                        "0 days 00:11:57    [[(39.76480458769947+0j), (-14.458886418182754...\n",
                        "0 days 00:11:58    [[(41.44310617633164+0j), (-14.505759847549935...\n",
                        "0 days 00:11:59    [[(40.858970559202135+0j), (-14.47855723214503...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(44.61700136587024+0j), (-16.796127152592785...\n",
                        "0 days 00:00:01    [[(45.129090772010386+0j), (-16.77164536575956...\n",
                        "0 days 00:00:02    [[(44.8563759252429+0j), (-16.775592356237574+...\n",
                        "0 days 00:00:03    [[(45.24653167836368+0j), (-16.819891825540523...\n",
                        "0 days 00:00:04    [[(44.38453970942646+0j), (-16.83082698005346+...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(48.60439418628812+0j), (-17.60430446009863+...\n",
                        "0 days 00:11:56    [[(47.793342001736164+0j), (-17.63543107303111...\n",
                        "0 days 00:11:57    [[(48.01993618905544+0j), (-17.626591382439678...\n",
                        "0 days 00:11:58    [[(47.77667411416769+0j), (-17.586355965576157...\n",
                        "0 days 00:11:59    [[(47.49790021777153+0j), (-17.60795682819737+...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(40.233470890671015+0j), (-14.41374224958887...\n",
                        "0 days 00:00:01    [[(39.21962377568707+0j), (-14.349308999918469...\n",
                        "0 days 00:00:02    [[(39.872615680098534+0j), (-14.38747160750936...\n",
                        "0 days 00:00:03    [[(40.0910504674539+0j), (-14.376663076067915+...\n",
                        "0 days 00:00:04    [[(40.38949045911431+0j), (-14.423397890909495...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(40.3367464505136+0j), (-14.403390133925663+...\n",
                        "0 days 00:11:56    [[(41.07549274340272+0j), (-14.336209617888457...\n",
                        "0 days 00:11:57    [[(40.44548284634948+0j), (-14.385147306795075...\n",
                        "0 days 00:11:58    [[(40.08386726304889+0j), (-14.37222526095833+...\n",
                        "0 days 00:11:59    [[(40.19947621040046+0j), (-14.354927173356007...\n",
                        "Freq: S, Length: 720, dtype: object\n",
                        "timestamps\n",
                        "0 days 00:00:00    [[(45.29651693068445+0j), (-16.55586914344145+...\n",
                        "0 days 00:00:01    [[(45.161346909590065+0j), (-16.52060658153170...\n",
                        "0 days 00:00:02    [[(44.78677447140217+0j), (-16.521525021647978...\n",
                        "0 days 00:00:03    [[(44.883205372840166+0j), (-16.4869646544945+...\n",
                        "0 days 00:00:04    [[(44.25466515682638+0j), (-16.494733289388073...\n",
                        "                                         ...                        \n",
                        "0 days 00:11:55    [[(43.92180763930082+0j), (-16.627776943629495...\n",
                        "0 days 00:11:56    [[(44.07643020898104+0j), (-16.688472640500848...\n",
                        "0 days 00:11:57    [[(43.75896250363439+0j), (-16.641021215002397...\n",
                        "0 days 00:11:58    [[(43.601893838495016+0j), (-16.66716924452550...\n",
                        "0 days 00:11:59    [[(43.268411736004055+0j), (-16.66110381967613...\n",
                        "Freq: S, Length: 720, dtype: object\n"
                    ]
                }
            ],
            "source": [
                "def process_freq_kidaq(file):\n",
                "\n",
                "    error_type_with_number = file.parts[8]\n",
                "    error_type = error_type_with_number.split(\" \")[0]\n",
                "    rpm = file.parts[10].split(\"r\")[0]\n",
                "    rpm_percent = file.parts[11].split(\"m\")[1].split(\"%\")[0]\n",
                "    \n",
                "    mdf = asammdf.MDF(file)\n",
                "    df = mdf.to_dataframe()\n",
                "    df.index = pd.to_timedelta(df.index, unit=\"s\")\n",
                "\n",
                "    resample_time = df.resample(\"1s\")\n",
                "\n",
                "    r = resample_time.aggregate(lambda sample: np.fft.fft)\n",
                "\n",
                "    \n",
                "    df_fft = pd.DataFrame(np.fft.fft(df))\n",
                "\n",
                "    df_fft.columns = df.columns\n",
                "    df_fft.index = df.index\n",
                "    df_fft.index = pd.to_timedelta(df_fft.index, unit=\"s\")\n",
                "    df_fft = df_fft.apply(np.abs)\n",
                "    resampled = df_fft.resample(\"1s\")\n",
                "\n",
                "    df_mean = resampled.mean().to_numpy()\n",
                "    df_range = resampled.max() - resampled.min()\n",
                "    df_range = df_range.to_numpy()\n",
                "    df_std = resampled.std().to_numpy()\n",
                "    df_iqr = resampled.quantile(0.75) - resampled.quantile(0.25)\n",
                "    df_iqr = df_iqr.to_numpy()\n",
                "    df_mean_median = resampled.mean() - resampled.median()\n",
                "    df_mean_median = df_mean_median.to_numpy()\n",
                "\n",
                "    data = np.concatenate((np.repeat([[error_type_with_number, error_type, rpm, rpm_percent]], df_mean.shape[0], axis=0), df_mean, df_range, df_std, df_iqr, df_mean_median), axis=1)\n",
                "\n",
                "    with open(\"fft_test.csv\", \"a\") as f:\n",
                "        for feature in data:\n",
                "            f.write(\";\".join(feature) + \"\\n\")    \n",
                "\n",
                "    \n",
                "\n",
                "\n",
                "\n",
                "for file in tqdm(raw_files):\n",
                "    df = process_freq_kidaq(file) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b0a3a714",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "171cabba",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d321ae3c36c34db4bfebd31f3c051fca",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/20 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "\n",
                "FREQ_WINDOWS = 16\n",
                "\n",
                "def process_freq_kidaq(file):\n",
                "\n",
                "    error_type_with_number = file.parts[8]\n",
                "    error_type = error_type_with_number.split(\" \")[0]\n",
                "    rpm = file.parts[10].split(\"r\")[0]\n",
                "    rpm_percent = file.parts[11].split(\"m\")[1].split(\"%\")[0]\n",
                "    \n",
                "    mdf = asammdf.MDF(file)\n",
                "    df = mdf.to_dataframe()\n",
                "    df = df.reset_index()\n",
                "\n",
                "    df = df[COLUMNS_KiDAQ]\n",
                "\n",
                "    df_features = None\n",
                "\n",
                "    windows = df.groupby(df.index // (int(win_sizes.value) * 20))\n",
                "\n",
                "    for _, window in windows:\n",
                "\n",
                "        for col in window.columns:\n",
                "            X = np.fft.fft(window[col])\n",
                "            amps = np.abs(X)\n",
                "\n",
                "            xf = np.fft.fftfreq(len(window[col]), 1 / 20000)\n",
                "\n",
                "            idxMax = np.argmax(amps)\n",
                "\n",
                "            if df_features is None:\n",
                "                df_features = np.concatenate(([xf[idxMax]], [amps[idxMax]]), axis=0)\n",
                "            else:\n",
                "                df_features = np.concatenate((df_features, [xf[idxMax]], [amps[idxMax]]), axis=0)\n",
                "\n",
                "            freqs_window_size = len(amps) / FREQ_WINDOWS\n",
                "\n",
                "            for x in range(FREQ_WINDOWS):\n",
                "                freq_window = amps[int(x*freqs_window_size):int((x+1)*freqs_window_size)]\n",
                "                df_features = np.concatenate((df_features, [np.max(freq_window, axis=0)], [np.average(freq_window, axis=0)], [np.mean(freq_window, axis=0)] ), axis=0)\n",
                "\n",
                "    df_features = np.concatenate(([error_type_with_number], [error_type], [rpm], [rpm_percent], df_features), axis=0) \n",
                "\n",
                "    with open(f\"data/freq_{raw_data_type}_features.csv\", \"w\") as f:\n",
                "        f.write(\";\".join(df_features))\n",
                "\n",
                "    # for _, window in windows:\n",
                "\n",
                "    #         for col in window.columns:\n",
                "    #             X = np.fft.fft(window[col])\n",
                "    #             amps = np.abs(X)\n",
                "\n",
                "    #             xf = np.fft.fftfreq(len(window[col]), 1 / 20000)\n",
                "\n",
                "    #             idxMax = np.argmax(amps)\n",
                "\n",
                "    #             # create a dataframe with two columns amps and xf\n",
                "    #             df_fft = pd.DataFrame({'amps': amps, 'xf': xf})\n",
                "\n",
                "    #             freqs_window_size = len(amps) / FREQ_WINDOWS\n",
                "\n",
                "    #             for x in range(FREQ_WINDOWS):\n",
                "    #                 freq_window = amps[int(x*freqs_window_size):int((x+1)*freqs_window_size)]\n",
                "    #                 window_features = {\n",
                "    #                     \"Fehlertyp\": error_type_with_number,\n",
                "    #                     \"Fehlertyp_allgemein\": error_type,\n",
                "    #                     \"rpm\": rpm,\n",
                "    #                     \"rpm%\": rpm_percent,\n",
                "    #                     \"xf_max\": xf[idxMax],\n",
                "    #                     \"amps_max\": amps[idxMax],\n",
                "    #                     \"amps_max_window\": np.max(freq_window, axis=0),\n",
                "    #                     \"amps_avg_window\": np.average(freq_window, axis=0),\n",
                "    #                     \"amps_mean_window\": np.mean(freq_window, axis=0)\n",
                "    #                 }\n",
                "\n",
                "    #                 if df_features is None:\n",
                "    #                     df_features = pd.DataFrame(window_features, index=[0])\n",
                "    #                 else:\n",
                "    #                     df_features = pd.concat([df_features, pd.DataFrame(window_features, index=[0])])\n",
                "\n",
                "\n",
                "    # if not pl.Path(f\"freq_{raw_data_type}_1_features.csv\").exists():\n",
                "    #     df_features.to_csv(f\"data/freq_{raw_data_type}_features.csv\", header=True, index=False, sep=\";\")\n",
                "    # else:\n",
                "         \n",
                "    #     df_features.to_csv(f\"freq_{raw_data_type}_1_features.csv\", mode='a', header=False, index=False, sep=\";\")\n",
                "\n",
                "\n",
                "        \n",
                "for file in tqdm(raw_files):\n",
                "    process_freq_kidaq(file)\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a5e02f6d",
            "metadata": {},
            "source": [
                "## Durch ausführen der folgenden Zelle, werden die Daten mit den ausgewählten Parametern vorbereitet und abgespeichert"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "877111cd",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "02f80592728f4e859314895281c25fd6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/540 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "\n",
                "RESULT_FILE = CWD / \"data\" / f\"{raw_data_type.value}_features.csv\"\n",
                "\n",
                "if raw_data_type.value == \"VIB\":\n",
                "    result = None\n",
                "    for file in tqdm(raw_files):\n",
                "        if \"VIB\" in file.name:\n",
                "            if result is None:\n",
                "                result = process_vib(file)\n",
                "            else:\n",
                "                result = pd.concat([result, process_vib(file)])\n",
                "\n",
                "\n",
                "    #create an ascending index to be able to pivot the dataframe\n",
                "    result = result.pivot(index=[\"ID\",\"Fehlertyp\", \"Fehlertyp_allgemein\", \"rpm\", \"rpm%\", \"version\"], columns=\"Aggregation\", values=\"Value\")\n",
                "    result = result.drop(columns=[\"ID\"])\n",
                "    # save the result to a csv file\n",
                "    result.to_csv(RESULT_FILE, sep=\";\")\n",
                "\n",
                "\n",
                "elif raw_data_type.value == \"KIDAQ\":\n",
                "    for file in tqdm(raw_files):\n",
                "        result = process_kidaq(file)\n",
                "\n",
                "\n",
                "    if result is not None:\n",
                "        if not pl.Path(RESULT_FILE).exists():\n",
                "            result.to_csv(RESULT_FILE, index=False, sep=\";\")\n",
                "        else:\n",
                "            result.to_csv(RESULT_FILE, mode=\"a\", header=False, index=False, sep=\";\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "e84cc0d7",
            "metadata": {},
            "source": [
                "# Die folgenden Zellen dienen zum Filtern des ausgewählten Datensatzes nach den gewünschten Parametern\n",
                "\n",
                "Hier lassen sich ausschnitte aus dem kompletten Feature-Set auswählen um zum Beispiel Training und Testdaten zu generieren"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "9da8dbc8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dce5053b06e84db9b374a275ebd902bb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Dropdown(description='Feature Type:', options=('KIDAQ', 'VIB'), value='KIDAQ')"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "feature_types = [\"KIDAQ\", \"VIB\"]\n",
                "\n",
                "f_type = widgets.Dropdown(\n",
                "    options=feature_types,\n",
                "    value=feature_types[0],\n",
                "    description=\"Feature Type:\",\n",
                "    disabled=False,\n",
                ")\n",
                "display(f_type)\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "28b85819",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1dd557a8cb1a4768ba41a49f6c39675e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "SelectMultiple(description='Error Type:', index=(0,), options=('Fehlausrichtung 1',), value=('Fehlausrichtung …"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b81a7398153d4a7a96238f5f3a00582e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "SelectMultiple(description='RPM:', index=(0, 1, 2, 3), options=(725, 1450, 2175, 2900), value=(725, 1450, 2175…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c21c0ce57ef04c38abaed1d86b0397e5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "SelectMultiple(description='RPM%:', index=(0, 1, 2, 3, 4), options=(0, 25, 50, 75, 100), value=(0, 25, 50, 75,…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "\n",
                "df_features = pd.read_csv(CWD / \"data\" / f\"{f_type.value}_features.csv\", sep=\",\")\n",
                "\n",
                "error_types = df_features[\"Fehlertyp\"].unique().tolist()\n",
                "rpm_values = [725, 1450, 2175, 2900]\n",
                "rpm_percent_values = [0, 25, 50, 75, 100]\n",
                "\n",
                "columns = df_features.columns.tolist()\n",
                "\n",
                "\n",
                "error_type = widgets.SelectMultiple(\n",
                "    options=error_types,\n",
                "    value=error_types,\n",
                "    description=\"Error Type:\",\n",
                "    disabled=False,\n",
                ")\n",
                "\n",
                "rpm = widgets.SelectMultiple(\n",
                "    options=rpm_values,\n",
                "    value=rpm_values,\n",
                "    description=\"RPM:\",\n",
                "    disabled=False,\n",
                ")\n",
                "\n",
                "rpm_percent = widgets.SelectMultiple(\n",
                "    options=rpm_percent_values,\n",
                "    value=rpm_percent_values,\n",
                "    description=\"RPM%:\",\n",
                "    disabled=False,\n",
                ")\n",
                "\n",
                "display(error_type)\n",
                "display(rpm)\n",
                "display(rpm_percent)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "e9bcd401",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4f65fc9c475c4a7d9e873ac9e3ce76ed",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Text(value='', description='File Name:', placeholder='Type something')"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "\n",
                "# filter the dataframe based on the selected rpm and rpm%\n",
                "df_features = df_features[df_features[\"Fehlertyp\"].isin(error_type.value)]\n",
                "df_features = df_features[df_features[\"rpm\"].isin(rpm.value)]\n",
                "df_features = df_features[df_features[\"rpm%\"].isin(rpm_percent.value)]\n",
                "\n",
                "# save the filtered dataframe to a csv file and let the user type in a name for the file\n",
                "file_name = widgets.Text(\n",
                "    value=\"\",\n",
                "    placeholder=\"Type something\",\n",
                "    description=\"File Name:\",\n",
                "    disabled=False,\n",
                ")\n",
                "display(file_name)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "2d310e51",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_features.to_csv(CWD / \"data\" / f\"{file_name.value}.csv\", index=False, sep=\";\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b8ed0170-f3d5-4287-8dd8-7439080d27af",
            "metadata": {},
            "source": [
                "## 4. Deskriptive/Explorative Datenanalyse [Philipp]\n",
                "\n",
                "- Plots\n",
                "- Beschreibung der Plots\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4b92fefe-672c-4bba-97c1-f78747ff1dc1",
            "metadata": {},
            "source": [
                "## 5. Machine Learning [Kevin]\n",
                "\n",
                "Multi-Selektion für:\n",
                "\n",
                "- Auswahl der Featuredateien (Train/Testdaten)\n",
                "- Auswahl des Learners\n",
                "- Konfiguration der Hyperparameter\n",
                "- Live-Validation des Models mit vorausgewählten Testdaten (Random-Search, ...)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8da6989",
            "metadata": {},
            "outputs": [],
            "source": [
                "# SELECT TRAINING AND TEST DATA\n",
                "featureDataDir = list(filter(lambda x: os.path.isfile(os.path.join(PATH_FEATURE_DATA, x)) and DEFAULT_RAW_DATA_TYPE in x.upper(), os.listdir(PATH_FEATURE_DATA)))\n",
                "\n",
                "modelDropdown = widgets.Dropdown(description=\"training features\")\n",
                "modelDropdown.options = featureDataDir\n",
                "selectedModelFile = None\n",
                "def onTrainigFileChange(change):\n",
                "    global selectedModelFile\n",
                "    selectedModelFile = change['new']\n",
                "modelDropdown.observe(onTrainigFileChange, names='value')\n",
                "display(modelDropdown)\n",
                "\n",
                "testFileDropdown = widgets.Dropdown(description=\"test features\")\n",
                "testFileDropdown.options = featureDataDir\n",
                "selectedTestFile = None\n",
                "def onTestFileChange(change):\n",
                "    global selectedTestFile\n",
                "    selectedTestFile = change['new']\n",
                "testFileDropdown.observe(onTestFileChange, names='value')\n",
                "display(testFileDropdown)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbbd27e2",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5e8f18d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# SET ML CONFIG\n",
                "FEATURE_TRAIN_FILE = PATH_FEATURE_DATA + selectedModelFile\n",
                "FEATURE_TEST_FILE = PATH_FEATURE_DATA + selectedTestFile\n",
                "\n",
                "DEFAULT_OPERATING_POINTS = OPERATING_POINT_FREQ + OPERATING_POINT_FLOW_RATE\n",
                "\n",
                "\n",
                "# DNN\n",
                "DNN_EXPLORATION_TARGET_VAL_ACCURACY = 0.9\n",
                "DNN_EXPLORATION_MAX_ITER = 1\n",
                "DNN_EXPLORATION_HIDDEN_LAYERS_MIN = 2\n",
                "DNN_EXPLORATION_HIDDEN_LAYERS_MAX = 4\n",
                "DNN_EXPLORATION_NEURONS_MIN = 8\n",
                "DNN_EXPLORATION_NEURONS_MAX = 64\n",
                "\n",
                "\n",
                "DNN_EARLY_STOPPING_PATIENCE = 50\n",
                "DNN_VERBOSE = 0\n",
                "DNN_EPOCHS = 100\n",
                "DNN_BATCH_SIZE = 32\n",
                "DNN_BATCH_NORMALIZATION = True\n",
                "\n",
                "\n",
                "# DT\n",
                "DT_MAX_DEPTH = 6\n",
                "DT_NUM_ESTIMATORS = 100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "51491a91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# LOAD DATA\n",
                "train_data = read_csv(FEATURE_TRAIN_FILE, header=None, delimiter=\",\", decimal='.', low_memory=False).values\n",
                "test_data = read_csv(FEATURE_TEST_FILE, header=None, delimiter=\",\", decimal='.', low_memory=False).values\n",
                "print(train_data[1:, :3])\n",
                "\n",
                "train_x, train_y = train_data[1:, 3:].astype('float32'), train_data[1:, :1]\n",
                "test_x, test_y = test_data[1:, 3:].astype('float32'), test_data[1:, :1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d6d7b343",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Decision Tree\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "\n",
                "labelEncoder = LabelEncoder()\n",
                "labelEncoder = labelEncoder.fit(np.ravel(train_y))\n",
                "label_encoded_train_y = labelEncoder.transform(np.ravel(train_y))\n",
                "label_encoded_test_y = labelEncoder.transform(np.ravel(test_y))\n",
                "\n",
                "\n",
                "xgb = XGBClassifier(\n",
                "    tree_method=\"hist\",\n",
                "    enable_categorical=True,\n",
                "    max_depth=DT_MAX_DEPTH,\n",
                "    n_estimators=DT_NUM_ESTIMATORS,\n",
                ")\n",
                "# fit model\n",
                "xgb.fit(train_x, label_encoded_train_y, eval_set=[(test_x, label_encoded_test_y)])\n",
                "\n",
                "\n",
                "preds = xgb.predict(test_x)\n",
                "accuracy = accuracy_score(label_encoded_test_y, preds)\n",
                "\n",
                "XGBClassifier.save_model(xgb, PATH_MODEL+\"dt.\"+str(round(time.time())))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f987c57a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Neural Network\n",
                "import json\n",
                "import random\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from tensorflow.keras import Sequential\n",
                "from tensorflow.keras.layers import Dense, InputLayer, BatchNormalization\n",
                "from tensorflow.keras.callbacks import EarlyStopping\n",
                "\n",
                "onehotencoder = OneHotEncoder()\n",
                "onehotencoder = onehotencoder.fit(train_y)\n",
                "onehot_encoded_train_y = onehotencoder.transform(train_y).toarray()\n",
                "onehot_encoded_test_y = onehotencoder.transform(test_y).toarray()\n",
                "\n",
                "exploration_results = []\n",
                "\n",
                "\n",
                "n_features = train_x.shape[1]\n",
                "categories = len(onehot_encoded_train_y[0])\n",
                "\n",
                "test_acc = 0.0\n",
                "model = Sequential()\n",
                "interation = 0\n",
                "while (\n",
                "    test_acc < DNN_EXPLORATION_TARGET_VAL_ACCURACY\n",
                "    and interation < DNN_EXPLORATION_MAX_ITER\n",
                "):\n",
                "    model = Sequential()\n",
                "    model.add(InputLayer(input_shape=(n_features,)))\n",
                "    model.add(BatchNormalization())\n",
                "    dense_count = random.randint(\n",
                "        DNN_EXPLORATION_HIDDEN_LAYERS_MIN, DNN_EXPLORATION_HIDDEN_LAYERS_MAX\n",
                "    )\n",
                "    dense_neurons = []\n",
                "    for i in range(0, dense_count):\n",
                "        neurons = random.randint(\n",
                "            DNN_EXPLORATION_NEURONS_MIN, DNN_EXPLORATION_NEURONS_MAX\n",
                "        )\n",
                "        dense_neurons.append(neurons)\n",
                "        model.add(Dense(neurons, activation=\"tanh\"))\n",
                "        model.add(BatchNormalization())\n",
                "    model.add(Dense(categories, activation=\"sigmoid\"))\n",
                "    model.compile(\n",
                "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
                "    )\n",
                "    model.fit(\n",
                "        train_x,\n",
                "        onehot_encoded_train_y,\n",
                "        epochs=DNN_EPOCHS,\n",
                "        batch_size=DNN_BATCH_SIZE,\n",
                "        verbose=1,\n",
                "        validation_data=(test_x, onehot_encoded_test_y),\n",
                "        callbacks=[\n",
                "            EarlyStopping(\n",
                "                monitor=\"val_loss\",\n",
                "                patience=DNN_EARLY_STOPPING_PATIENCE,\n",
                "                restore_best_weights=True,\n",
                "            )\n",
                "        ],\n",
                "    )\n",
                "\n",
                "    train_loss, train_acc = model.evaluate(train_x, onehot_encoded_train_y)\n",
                "    test_loss, test_acc = model.evaluate(test_x, onehot_encoded_test_y)\n",
                "\n",
                "    exploration_results.append(\n",
                "        {\n",
                "            \"dense_count\": dense_count,\n",
                "            \"dense_neurons\": dense_neurons,\n",
                "            \"train_loss\": train_loss,\n",
                "            \"train_acc\": train_acc,\n",
                "            \"test_loss\": test_loss,\n",
                "            \"test_acc\": test_acc,\n",
                "        }\n",
                "    )\n",
                "    interation += 1\n",
                "\n",
                "modelName = \"dnn.\" + str(round(time.time()))\n",
                "model.save(PATH_MODEL + modelName)\n",
                "\n",
                "with open(PATH_EXPLORATION_DATA + modelName + \".exploration_results.json\", \"w\") as f:\n",
                "    json.dump(exploration_results, f, indent=4)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "615dfc90-2798-42fe-8001-7be9ea78aa35",
            "metadata": {},
            "source": [
                "## 6. Modelanalyse des Learners [Kevin]\n",
                "\n",
                "- Vorherige Auswahl eines Learners\n",
                "- Feature Importance\n",
                "- Korrelationsmatrix\n",
                "- Konfusionsmatrix\n",
                "- Post-Validation des Models mit auswählbaren Daten\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "72ea0d36",
            "metadata": {},
            "outputs": [],
            "source": [
                "# SELECT LEARNER AND TEST DATA\n",
                "featureDataDir = list(filter(lambda x: os.path.isfile(os.path.join(PATH_FEATURE_DATA, x)) and DEFAULT_RAW_DATA_TYPE in x.upper(), os.listdir(PATH_FEATURE_DATA)))\n",
                "modelDir = os.listdir(PATH_MODEL)\n",
                "\n",
                "modelDropdown = widgets.Dropdown(description=\"model\")\n",
                "modelDropdown.options = modelDir\n",
                "selectedModelFile = None\n",
                "def onTrainigFileChange(change):\n",
                "    global selectedModelFile\n",
                "    selectedModelFile = change['new']\n",
                "modelDropdown.observe(onTrainigFileChange, names='value')\n",
                "display(modelDropdown)\n",
                "\n",
                "testFileDropdown = widgets.Dropdown(description=\"test data\")\n",
                "testFileDropdown.options = featureDataDir\n",
                "selectedTestFile = None\n",
                "def onTestFileChange(change):\n",
                "    global selectedTestFile\n",
                "    selectedTestFile = change['new']\n",
                "testFileDropdown.observe(onTestFileChange, names='value')\n",
                "display(testFileDropdown)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e3540ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ANALYZE MODEL\n",
                "from matplotlib import pyplot\n",
                "from tensorflow import math as tfmath\n",
                "import tensorflow_probability as tfp\n",
                "import eli5\n",
                "from eli5.sklearn import PermutationImportance\n",
                "\n",
                "conf_matrix = tfmath.confusion_matrix(np.argmax(y_test, axis=1), np.argmax(result, axis=1))\n",
                "pyplot.matshow(conf_matrix, 1)\n",
                "for (x, y), value in np.ndenumerate(conf_matrix):\n",
                "    pyplot.text(y, x, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
                "pyplot.show()\n",
                "\n",
                "\n",
                "print('Test Accuracy: %.3f' % test_acc)\n",
                "\n",
                "\n",
                "corr_matrix = tfp.stats.correlation(X_test)\n",
                "pyplot.matshow(corr_matrix)\n",
                "pyplot.show()\n",
                "\n",
                "perm = PermutationImportance(model, scoring=\"neg_mean_squared_error\", random_state=1).fit(X_test, y_test)\n",
                "print(eli5.format_as_text(eli5.explain_weights(perm, feature_names=feature_names)))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "390a4a00-cdc0-4fae-bd1f-e92cd875dec1",
            "metadata": {},
            "source": [
                "## 7. Statische Interpretation des Resultats\n",
                "\n",
                "- Welches Ergebnis haben wir erzielt und wie kann man es anwenden?\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
