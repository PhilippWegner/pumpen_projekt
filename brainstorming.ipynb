{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5a94bd2-a922-4b01-a9b9-7658e41f6036",
   "metadata": {},
   "source": [
    "# Aufbau der Notebooks [Philipp]\n",
    "\n",
    "- Multivalue bei Notebooks angucken\n",
    "- Wie installiere ich den \"scheiß\"\n",
    "- Widgets: https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3394772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import ipywidgets as widgets\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268ea6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f03027a325f4cc2b94b8cedc6099713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TagsInput(value=['TEST_NAME', 'TEST_TYPE', 'RPM', 'FLOW_RATE', 'P1', 'P2'], allow_duplicates=False, allowed_ta…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Globals\n",
    "\n",
    "PATH_RAW_DATA = \"./raw/\"\n",
    "PATH_FEATURE_DATA = \"./features/\"\n",
    "PATH_EXPLORATION_DATA = \"./exploration/\"\n",
    "PATH_MODEL = \"./model/\"\n",
    "DATA_SOURCE_KIDAQ = [\"TEST_NAME\", \"TEST_TYPE\", \"RPM\", \"FLOW_RATE\", \"P1\", \"P2\"]\n",
    "\n",
    "DATA_SOURCE_VID = [\n",
    "    \"TEST_NAME\",\n",
    "    \"TEST_TYPE\",\n",
    "    \"RPM\",\n",
    "    \"FLOW_RATE\",\n",
    "    \"S1\",\n",
    "    \"S2\",\n",
    "    \"S3\",\n",
    "    \"S4\",\n",
    "    \"S5\",\n",
    "    \"S6\",\n",
    "    \"S7\",\n",
    "    \"S8\",\n",
    "]\n",
    "FEATURE = [\n",
    "    \"STD\",\n",
    "    \"RANGE\",\n",
    "    \"IQR\",\n",
    "    \"MEAN_MEDIAN\",\n",
    "    \"FFT\",\n",
    "]\n",
    "OPERATING_POINT_FREQ = [\"RPM725\", \"RPM1450\", \"RPM2175\", \"RPM2900\"]\n",
    "OPERATING_POINT_FLOW_RATE = [\"PCT0\", \"PCT25\", \"PCT50\", \"PCT75\", \"PCT100\"]\n",
    "\n",
    "LEARNER = Enum(\"LEARNER\", [\"DNN\", \"DT\"])\n",
    "\n",
    "DEFAULT_LEARNER = LEARNER.DNN\n",
    "DEFAULT_RAW_DATA = DATA_SOURCE_KIDAQ\n",
    "print(widgets.__version__)\n",
    "tags = widgets.TagsInput(\n",
    "    value=DEFAULT_RAW_DATA, allowed_tags=DEFAULT_RAW_DATA, allow_duplicates=False\n",
    ")\n",
    "tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d08d88a7-0fc1-4c7a-91f7-df5aa0a4f9a2",
   "metadata": {},
   "source": [
    "## 1. Aufgabe und Daten erklären/beschreiben [Philipp]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6efc6220-a14b-4ff0-b0d8-66ba17569050",
   "metadata": {},
   "source": [
    "## 3. Preprocessing [Valerij]\n",
    "\n",
    "Aufgeteilt nach KIDAQ und VIB (separat um es einfach zu halten)\n",
    "\n",
    "- Auswahl der Fenstergröße in Millisekunden\n",
    "- Auswahl der Abtastrate\n",
    "- Multi-Selektion der Aggregation (avg, mean, std, ...)\n",
    "- Frequenzanalyse\n",
    "- Fourier-Transformation\n",
    "- Fenstergröße nach Frequenzbereichen\n",
    "\n",
    "### 3.1 Vorbereitung der Tainings- und Testdaten\n",
    "\n",
    "Multi-Selektion für:\n",
    "\n",
    "- Features\n",
    "- Betriebspunkte (RPM/FLOWRATE)\n",
    "- Klassifikationsarten (Szenario / Testdurchlauf)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8ed0170-f3d5-4287-8dd8-7439080d27af",
   "metadata": {},
   "source": [
    "## 4. Deskriptive/Explorative Datenanalyse [Philipp]\n",
    "\n",
    "- Plots\n",
    "- Beschreibung der Plots\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b92fefe-672c-4bba-97c1-f78747ff1dc1",
   "metadata": {},
   "source": [
    "## 5. Machine Learning [Kevin]\n",
    "\n",
    "Multi-Selektion für:\n",
    "\n",
    "- Auswahl der Featuredateien (Train/Testdaten)\n",
    "- Auswahl des Learners\n",
    "- Konfiguration der Hyperparameter\n",
    "- Live-Validation des Models mit vorausgewählten Testdaten (Random-Search, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8f18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TRAIN_FILE = \"train.csv\"\n",
    "FEATURE_TEST_FILE = \"test.csv\"\n",
    "\n",
    "DEFAULT_OPERATING_POINTS = OPERATING_POINT_FREQ + OPERATING_POINT_FLOW_RATE\n",
    "\n",
    "\n",
    "# DNN\n",
    "DNN_EXPLORATION_TARGET_VAL_ACCURACY = 0.9\n",
    "DNN_EXPLORATION_MAX_ITER = 100\n",
    "DNN_EXPLORATION_HIDDEN_LAYERS_MIN = 2\n",
    "DNN_EXPLORATION_HIDDEN_LAYERS_MAX = 4\n",
    "DNN_EXPLORATION_NEURONS_MIN = 8\n",
    "DNN_EXPLORATION_NEURONS_MAX = 64\n",
    "\n",
    "\n",
    "DNN_EARLY_STOPPING_PATIENCE = 50\n",
    "DNN_VERBOSE = 0\n",
    "DNN_EPOCHS = 100\n",
    "DNN_BATCH_SIZE = 32\n",
    "DNN_BATCH_NORMALIZATION = True\n",
    "\n",
    "\n",
    "# DT\n",
    "DT_MAX_DEPTH = 6\n",
    "DT_NUM_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51491a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_csv(FEATURE_TRAIN_FILE, header=None, delimiter=\";\")\n",
    "test_data = read_csv(FEATURE_TEST_FILE, header=None, delimiter=\";\")\n",
    "\n",
    "\n",
    "train_x, train_y = train_data[:, 2:], train_data[:, 1:2]\n",
    "test_x, test_y = test_data[:, 2:], test_data[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder = labelEncoder.fit(train_y)\n",
    "label_encoded_train_y = labelEncoder.transform(train_y)\n",
    "label_encoded_test_y = labelEncoder.transform(test_y)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,\n",
    "    max_depth=DT_MAX_DEPTH,\n",
    "    n_estimators=DT_NUM_ESTIMATORS,\n",
    ")\n",
    "# fit model\n",
    "xgb.fit(train_x, label_encoded_train_y, eval_set=[(test_x, label_encoded_test_y)])\n",
    "\n",
    "\n",
    "preds = xgb.predict(test_x)\n",
    "accuracy = accuracy_score(label_encoded_test_y, preds)\n",
    "\n",
    "xgb.save_model(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, BatchNormalization\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "onehotencoder = onehotencoder.fit(train_y)\n",
    "onehot_encoded_train_y = onehotencoder.transform(train_y).toarray()\n",
    "onehot_encoded_test_y = onehotencoder.transform(test_y).toarray()\n",
    "\n",
    "exploration_results = []\n",
    "\n",
    "\n",
    "n_features = train_x.shape[1]\n",
    "categories = len(onehot_encoded_train_y[0])\n",
    "\n",
    "test_acc = 0.0\n",
    "model = Sequential()\n",
    "interation = 0\n",
    "while (\n",
    "    test_acc < DNN_EXPLORATION_TARGET_VAL_ACCURACY\n",
    "    and interation < DNN_EXPLORATION_MAX_ITER\n",
    "):\n",
    "    model.add(InputLayer(input_shape=(n_features,)))\n",
    "    model.add(BatchNormalization())\n",
    "    dense_count = random.randint(\n",
    "        DNN_EXPLORATION_HIDDEN_LAYERS_MIN, DNN_EXPLORATION_HIDDEN_LAYERS_MAX\n",
    "    )\n",
    "    dense_neurons = []\n",
    "    for i in range(0, dense_count):\n",
    "        neurons = random.randint(\n",
    "            DNN_EXPLORATION_NEURONS_MIN, DNN_EXPLORATION_NEURONS_MAX\n",
    "        )\n",
    "        dense_neurons.append(neurons)\n",
    "        model.add(Dense(neurons, activation=\"tanh\"))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(categories, activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.fit(\n",
    "        train_x,\n",
    "        onehot_encoded_train_y,\n",
    "        epochs=DNN_EPOCHS,\n",
    "        batch_size=DNN_BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        validation_data=(test_x, onehot_encoded_test_y),\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=DNN_EARLY_STOPPING_PATIENCE,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(train_x, onehot_encoded_train_y)\n",
    "    test_loss, test_acc = model.evaluate(test_x, onehot_encoded_test_y)\n",
    "\n",
    "    exploration_results.append(\n",
    "        {\n",
    "            \"dense_count\": dense_count,\n",
    "            \"dense_neurons\": dense_neurons,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "        }\n",
    "    )\n",
    "    interation += 1\n",
    "    model = Sequential()\n",
    "\n",
    "model.save(PATH_MODEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "615dfc90-2798-42fe-8001-7be9ea78aa35",
   "metadata": {},
   "source": [
    "## 6. Modelanalyse des Learners [Kevin]\n",
    "\n",
    "- Vorherige Auswahl eines Learners\n",
    "- Feature Importance\n",
    "- Korrelationsmatrix\n",
    "- Konfusionsmatrix\n",
    "- Post-Validation des Models mit auswählbaren Daten\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "390a4a00-cdc0-4fae-bd1f-e92cd875dec1",
   "metadata": {},
   "source": [
    "## 7. Statische Interpretation des Resultats\n",
    "\n",
    "- Welches Ergebnis haben wir erzielt und wie kann man es anwenden?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
