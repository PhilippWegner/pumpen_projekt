{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a94bd2-a922-4b01-a9b9-7658e41f6036",
   "metadata": {},
   "source": [
    "# Aufbau der Notebooks [Philipp]\n",
    "\n",
    "- Multivalue bei Notebooks angucken\n",
    "- Wie installiere ich den \"scheiß\"\n",
    "- Widgets: https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3394772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import ipywidgets as widgets\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import asammdf\n",
    "from IPython.display import display\n"
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "268ea6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74b4be1ac40498a8722d980ba284406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TagsInput(value=['TEST_NAME', 'TEST_TYPE', 'RPM', 'FLOW_RATE', 'P1', 'P2'], allow_duplicates=False, allowed_ta…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Globals\n",
    "\n",
    "PATH_RAW_DATA = \"./data/raw/\"\n",
    "PATH_FEATURE_DATA = \"./data/\"\n",
    "PATH_EXPLORATION_DATA = \"./exploration/\"\n",
    "PATH_MODEL = \"./models/\"\n",
    "DATA_SOURCE_KIDAQ = [\"TEST_NAME\", \"TEST_TYPE\", \"RPM\", \"FLOW_RATE\", \"P1\", \"P2\"]\n",
    "RAW_DATA_TYPE = [\"KIDAQ\", \"VIB\"]\n",
    "\n",
    "DATA_SOURCE_VID = [\n",
    "    \"TEST_NAME\",\n",
    "    \"TEST_TYPE\",\n",
    "    \"RPM\",\n",
    "    \"FLOW_RATE\",\n",
    "    \"S1\",\n",
    "    \"S2\",\n",
    "    \"S3\",\n",
    "    \"S4\",\n",
    "    \"S5\",\n",
    "    \"S6\",\n",
    "    \"S7\",\n",
    "    \"S8\",\n",
    "]\n",
    "FEATURE = [\n",
    "    \"STD\",\n",
    "    \"RANGE\",\n",
    "    \"IQR\",\n",
    "    \"MEAN_MEDIAN\",\n",
    "    \"FFT\",\n",
    "]\n",
    "OPERATING_POINT_FREQ = [725, 1450, 2175, 2900]\n",
    "OPERATING_POINT_FLOW_RATE = [0, 25, 50, 75, 100]\n",
    "\n",
    "LEARNER = Enum(\"LEARNER\", [\"DNN\", \"DT\"])\n",
    "\n",
    "DEFAULT_LEARNER = LEARNER.DNN\n",
    "DEFAULT_RAW_DATA_TYPE = RAW_DATA_TYPE[1]\n",
    "DEFAULT_RAW_DATA = DATA_SOURCE_KIDAQ\n",
    "\n",
    "DEFAULT_CLASS_LABEL = \"TEST_TYPE\"\n",
    "\n",
    "tags = widgets.TagsInput(\n",
    "    value=DEFAULT_RAW_DATA, allowed_tags=DEFAULT_RAW_DATA, allow_duplicates=False\n",
    ")\n",
    "display(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf4db6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d08d88a7-0fc1-4c7a-91f7-df5aa0a4f9a2",
   "metadata": {},
   "source": [
    "## 1. Aufgabe und Daten erklären/beschreiben [Philipp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc6220-a14b-4ff0-b0d8-66ba17569050",
   "metadata": {},
   "source": [
    "## 3. Preprocessing [Valerij]\n",
    "\n",
    "Aufgeteilt nach KIDAQ und VIB (separat um es einfach zu halten)\n",
    "\n",
    "- Auswahl der Fenstergröße in Millisekunden\n",
    "- Auswahl der Abtastrate\n",
    "- Multi-Selektion der Aggregation (avg, mean, std, ...)\n",
    "- Frequenzanalyse\n",
    "- Fourier-Transformation\n",
    "- Fenstergröße nach Frequenzbereichen\n",
    "\n",
    "### 3.1 Vorbereitung der Tainings- und Testdaten\n",
    "\n",
    "Multi-Selektion für:\n",
    "\n",
    "- Features\n",
    "- Betriebspunkte (RPM/FLOWRATE)\n",
    "- Klassifikationsarten (Szenario / Testdurchlauf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103ea4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abd93f8cd414f69850fb7f46aac73df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Window size in ms: ', options=('100', '200', '300', '400', '500', '600', '700', '800', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4890c892ad324fc6a1a848500c1272a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Aggregations:', options=('mean', 'std', 'min', 'max', 'median'), value=())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be985d9aa9b4c8ebda6b8be2c178534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TagsInput(value=['mean', 'std', 'min', 'max', 'median'], allow_duplicates=False, allowed_tags=['mean', 'std', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "WINDOW_SIZE_MS = [\"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\", \"800\",\"900\",\"1000\"]\n",
    "AGGREGATIONS = [\"mean\", \"std\", \"min\", \"max\", \"median\"]\n",
    "\n",
    "win_sizes = widgets.Dropdown(\n",
    "    placeholder= \"Choose the window size in ms\",\n",
    "    options = WINDOW_SIZE_MS,\n",
    "    description = \"Window size in ms: \",\n",
    "    ensure_option=True,\n",
    "    disabled = False\n",
    ")\n",
    "display(win_sizes)\n",
    "\n",
    "aggregations = widgets.SelectMultiple(\n",
    "    options = AGGREGATIONS,\n",
    "    description = \"Aggregations:\",\n",
    "    disabled = False\n",
    ")\n",
    "display(aggregations)\n",
    "\n",
    "aggs = widgets.TagsInput(\n",
    "    value=AGGREGATIONS,\n",
    "    allowed_tags=AGGREGATIONS,\n",
    "    allow_duplicates=False,\n",
    "    disabled=False\n",
    ")\n",
    "display(aggs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38d30db2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.merge() missing 1 required positional argument: 'right'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         features \u001b[39m=\u001b[39m window\u001b[39m.\u001b[39magg(aggregations\u001b[39m.\u001b[39mvalue)\n\u001b[0;32m     15\u001b[0m         pivot \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mmerge()\n\u001b[1;32m---> 17\u001b[0m process_file(\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/Valer/Documents/pumpen_projekt/725rpm0\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m.mf4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[20], line 15\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m _, window \u001b[39min\u001b[39;00m windows:\n\u001b[0;32m     14\u001b[0m     features \u001b[39m=\u001b[39m window\u001b[39m.\u001b[39magg(aggregations\u001b[39m.\u001b[39mvalue)\n\u001b[1;32m---> 15\u001b[0m     pivot \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39;49mmerge()\n",
      "\u001b[1;31mTypeError\u001b[0m: DataFrame.merge() missing 1 required positional argument: 'right'"
     ]
    }
   ],
   "source": [
    "COLUMNS=[\n",
    "    \"p1\",\n",
    "    \"p2\",\n",
    "    \"a1\",\n",
    "    \"T2\",\n",
    "    \"T1\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def process_file(file):\n",
    "    \n",
    "    error_type = \"\"\n",
    "    \n",
    "    mdf = asammdf.MDF(file)\n",
    "    df = mdf.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df = df[COLUMNS]\n",
    "\n",
    "    df_features = None\n",
    "    windows = df.groupby(df.index // (int(win_sizes.value) * 20))\n",
    "\n",
    "    for _, window in windows:\n",
    "\n",
    "        features = {\"Fehlertyp\": error_type}\n",
    "\n",
    "        for agg in aggs.value:\n",
    "            match agg:\n",
    "                case \"mean\":\n",
    "                    features[\"p1_mean\"] = window[\"p1\"].mean()\n",
    "                    features[\"p2_mean\"] = window[\"p2\"].mean()\n",
    "                    features[\"a1_mean\"] = window[\"a1\"].mean()\n",
    "                    features[\"T2_mean\"] = window[\"T2\"].mean()\n",
    "                    features[\"T1_mean\"] = window[\"T1\"].mean()\n",
    "                case \"std\":\n",
    "                    features[\"p1_std\"] = window[\"p1\"].std()\n",
    "                    features[\"p2_std\"] = window[\"p2\"].std()\n",
    "                    features[\"a1_std\"] = window[\"a1\"].std()\n",
    "                    features[\"T2_std\"] = window[\"T2\"].std()\n",
    "                    features[\"T1_std\"] = window[\"T1\"].std()\n",
    "                case \"min\":\n",
    "                    features[\"p1_min\"] = window[\"p1\"].min()\n",
    "                    features[\"p2_min\"] = window[\"p2\"].min()\n",
    "                    features[\"a1_min\"] = window[\"a1\"].min()\n",
    "                    features[\"T2_min\"] = window[\"T2\"].min()\n",
    "                    features[\"T1_min\"] = window[\"T1\"].min()\n",
    "                case \"max\":\n",
    "                    features[\"p1_max\"] =window[\"p1\"].max()\n",
    "                    features[\"p2_max\"] =window[\"p2\"].max()\n",
    "                    features[\"a1_max\"] =window[\"a1\"].max()\n",
    "                    features[\"T2_max\"] =window[\"T2\"].max()\n",
    "                    features[\"T1_max\"] =window[\"T1\"].max()\n",
    "                case \"median\":\n",
    "                    features[\"p1_median\"] =  window[\"p1\"].median()\n",
    "                    features[\"p2_median\"] =  window[\"p2\"].median()\n",
    "                    features[\"a1_median\"] =  window[\"a1\"].median()\n",
    "                    features[\"T2_median\"] =  window[\"T2\"].median()\n",
    "                    features[\"T1_median\"] =  window[\"T1\"].median()\n",
    "                case _:\n",
    "                    error_type = \"Aggregation not found\"\n",
    "\n",
    "        if df_features is None:\n",
    "            df_features = pd.DataFrame(features)    \n",
    "        else:\n",
    "            df_features = pd.concat([df_features, pd.DataFrame(features)])\n",
    "\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "process_file(\"C:/Users/Valer/Documents/pumpen_projekt/725rpm0%.mf4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed0170-f3d5-4287-8dd8-7439080d27af",
   "metadata": {},
   "source": [
    "## 4. Deskriptive/Explorative Datenanalyse [Philipp]\n",
    "\n",
    "- Plots\n",
    "- Beschreibung der Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92fefe-672c-4bba-97c1-f78747ff1dc1",
   "metadata": {},
   "source": [
    "## 5. Machine Learning [Kevin]\n",
    "\n",
    "Multi-Selektion für:\n",
    "\n",
    "- Auswahl der Featuredateien (Train/Testdaten)\n",
    "- Auswahl des Learners\n",
    "- Konfiguration der Hyperparameter\n",
    "- Live-Validation des Models mit vorausgewählten Testdaten (Random-Search, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8da6989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932a081eda6f43b68a5b53425d8b23b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='training features', options=('vib.setup1.csv', 'vib.setup2.csv'), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a126ce143a214c5da31bf2e855cf0dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='test features', options=('vib.setup1.csv', 'vib.setup2.csv'), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SELECT TRAINING AND TEST DATA\n",
    "featureDataDir = list(filter(lambda x: os.path.isfile(os.path.join(PATH_FEATURE_DATA, x)) and DEFAULT_RAW_DATA_TYPE in x.upper(), os.listdir(PATH_FEATURE_DATA)))\n",
    "\n",
    "modelDropdown = widgets.Dropdown(description=\"training features\")\n",
    "modelDropdown.options = featureDataDir\n",
    "selectedModelFile = None\n",
    "def onTrainigFileChange(change):\n",
    "    global selectedModelFile\n",
    "    selectedModelFile = change['new']\n",
    "modelDropdown.observe(onTrainigFileChange, names='value')\n",
    "display(modelDropdown)\n",
    "\n",
    "testFileDropdown = widgets.Dropdown(description=\"test features\")\n",
    "testFileDropdown.options = featureDataDir\n",
    "selectedTestFile = None\n",
    "def onTestFileChange(change):\n",
    "    global selectedTestFile\n",
    "    selectedTestFile = change['new']\n",
    "testFileDropdown.observe(onTestFileChange, names='value')\n",
    "display(testFileDropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e8f18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET ML CONFIG\n",
    "FEATURE_TRAIN_FILE = PATH_FEATURE_DATA + selectedModelFile\n",
    "FEATURE_TEST_FILE = PATH_FEATURE_DATA + selectedTestFile\n",
    "\n",
    "DEFAULT_OPERATING_POINTS = OPERATING_POINT_FREQ + OPERATING_POINT_FLOW_RATE\n",
    "\n",
    "\n",
    "# DNN\n",
    "DNN_EXPLORATION_TARGET_VAL_ACCURACY = 0.9\n",
    "DNN_EXPLORATION_MAX_ITER = 1\n",
    "DNN_EXPLORATION_HIDDEN_LAYERS_MIN = 2\n",
    "DNN_EXPLORATION_HIDDEN_LAYERS_MAX = 4\n",
    "DNN_EXPLORATION_NEURONS_MIN = 8\n",
    "DNN_EXPLORATION_NEURONS_MAX = 64\n",
    "\n",
    "\n",
    "DNN_EARLY_STOPPING_PATIENCE = 50\n",
    "DNN_VERBOSE = 0\n",
    "DNN_EPOCHS = 100\n",
    "DNN_BATCH_SIZE = 32\n",
    "DNN_BATCH_NORMALIZATION = True\n",
    "\n",
    "\n",
    "# DT\n",
    "DT_MAX_DEPTH = 6\n",
    "DT_NUM_ESTIMATORS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51491a91",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[39m=\u001b[39m read_csv(FEATURE_TRAIN_FILE, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m test_data \u001b[39m=\u001b[39m read_csv(FEATURE_TEST_FILE, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m train_x, train_y \u001b[39m=\u001b[39m train_data[:, \u001b[39m2\u001b[39m:], train_data[:, \u001b[39m1\u001b[39m:\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "train_data = read_csv(FEATURE_TRAIN_FILE, header=None, delimiter=\";\").values\n",
    "test_data = read_csv(FEATURE_TEST_FILE, header=None, delimiter=\";\").values\n",
    "\n",
    "train_x, train_y = train_data[:, 2:].astype('float32'), train_data[:, 1:2]\n",
    "test_x, test_y = test_data[:, 2:].astype('float32'), test_data[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6d7b343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.27518\n",
      "[1]\tvalidation_0-mlogloss:1.28511\n",
      "[2]\tvalidation_0-mlogloss:1.21706\n",
      "[3]\tvalidation_0-mlogloss:1.21787\n",
      "[4]\tvalidation_0-mlogloss:1.24143\n",
      "[5]\tvalidation_0-mlogloss:1.27339\n",
      "[6]\tvalidation_0-mlogloss:1.32524\n",
      "[7]\tvalidation_0-mlogloss:1.42268\n",
      "[8]\tvalidation_0-mlogloss:1.52952\n",
      "[9]\tvalidation_0-mlogloss:1.59830\n",
      "[10]\tvalidation_0-mlogloss:1.63602\n",
      "[11]\tvalidation_0-mlogloss:1.74402\n",
      "[12]\tvalidation_0-mlogloss:1.85493\n",
      "[13]\tvalidation_0-mlogloss:1.96412\n",
      "[14]\tvalidation_0-mlogloss:2.07208\n",
      "[15]\tvalidation_0-mlogloss:2.17972\n",
      "[16]\tvalidation_0-mlogloss:2.27525\n",
      "[17]\tvalidation_0-mlogloss:2.33593\n",
      "[18]\tvalidation_0-mlogloss:2.40999\n",
      "[19]\tvalidation_0-mlogloss:2.50217\n",
      "[20]\tvalidation_0-mlogloss:2.58418\n",
      "[21]\tvalidation_0-mlogloss:2.61032\n",
      "[22]\tvalidation_0-mlogloss:2.69617\n",
      "[23]\tvalidation_0-mlogloss:2.71945\n",
      "[24]\tvalidation_0-mlogloss:2.76588\n",
      "[25]\tvalidation_0-mlogloss:2.81289\n",
      "[26]\tvalidation_0-mlogloss:2.87667\n",
      "[27]\tvalidation_0-mlogloss:2.92785\n",
      "[28]\tvalidation_0-mlogloss:2.94293\n",
      "[29]\tvalidation_0-mlogloss:2.98559\n",
      "[30]\tvalidation_0-mlogloss:3.01484\n",
      "[31]\tvalidation_0-mlogloss:3.01775\n",
      "[32]\tvalidation_0-mlogloss:3.03293\n",
      "[33]\tvalidation_0-mlogloss:3.07673\n",
      "[34]\tvalidation_0-mlogloss:3.09446\n",
      "[35]\tvalidation_0-mlogloss:3.12543\n",
      "[36]\tvalidation_0-mlogloss:3.14833\n",
      "[37]\tvalidation_0-mlogloss:3.18620\n",
      "[38]\tvalidation_0-mlogloss:3.20047\n",
      "[39]\tvalidation_0-mlogloss:3.20917\n",
      "[40]\tvalidation_0-mlogloss:3.23984\n",
      "[41]\tvalidation_0-mlogloss:3.28024\n",
      "[42]\tvalidation_0-mlogloss:3.26218\n",
      "[43]\tvalidation_0-mlogloss:3.27050\n",
      "[44]\tvalidation_0-mlogloss:3.29505\n",
      "[45]\tvalidation_0-mlogloss:3.27852\n",
      "[46]\tvalidation_0-mlogloss:3.29240\n",
      "[47]\tvalidation_0-mlogloss:3.30211\n",
      "[48]\tvalidation_0-mlogloss:3.31889\n",
      "[49]\tvalidation_0-mlogloss:3.33950\n",
      "[50]\tvalidation_0-mlogloss:3.37553\n",
      "[51]\tvalidation_0-mlogloss:3.38780\n",
      "[52]\tvalidation_0-mlogloss:3.40539\n",
      "[53]\tvalidation_0-mlogloss:3.40892\n",
      "[54]\tvalidation_0-mlogloss:3.43942\n",
      "[55]\tvalidation_0-mlogloss:3.45333\n",
      "[56]\tvalidation_0-mlogloss:3.44603\n",
      "[57]\tvalidation_0-mlogloss:3.45842\n",
      "[58]\tvalidation_0-mlogloss:3.45404\n",
      "[59]\tvalidation_0-mlogloss:3.47440\n",
      "[60]\tvalidation_0-mlogloss:3.49729\n",
      "[61]\tvalidation_0-mlogloss:3.51504\n",
      "[62]\tvalidation_0-mlogloss:3.53583\n",
      "[63]\tvalidation_0-mlogloss:3.51728\n",
      "[64]\tvalidation_0-mlogloss:3.52239\n",
      "[65]\tvalidation_0-mlogloss:3.52288\n",
      "[66]\tvalidation_0-mlogloss:3.53591\n",
      "[67]\tvalidation_0-mlogloss:3.54703\n",
      "[68]\tvalidation_0-mlogloss:3.56848\n",
      "[69]\tvalidation_0-mlogloss:3.58235\n",
      "[70]\tvalidation_0-mlogloss:3.59416\n",
      "[71]\tvalidation_0-mlogloss:3.60413\n",
      "[72]\tvalidation_0-mlogloss:3.61567\n",
      "[73]\tvalidation_0-mlogloss:3.63527\n",
      "[74]\tvalidation_0-mlogloss:3.63634\n",
      "[75]\tvalidation_0-mlogloss:3.64793\n",
      "[76]\tvalidation_0-mlogloss:3.65760\n",
      "[77]\tvalidation_0-mlogloss:3.66923\n",
      "[78]\tvalidation_0-mlogloss:3.68312\n",
      "[79]\tvalidation_0-mlogloss:3.69253\n",
      "[80]\tvalidation_0-mlogloss:3.69621\n",
      "[81]\tvalidation_0-mlogloss:3.71290\n",
      "[82]\tvalidation_0-mlogloss:3.72163\n",
      "[83]\tvalidation_0-mlogloss:3.72559\n",
      "[84]\tvalidation_0-mlogloss:3.72136\n",
      "[85]\tvalidation_0-mlogloss:3.73509\n",
      "[86]\tvalidation_0-mlogloss:3.74352\n",
      "[87]\tvalidation_0-mlogloss:3.73887\n",
      "[88]\tvalidation_0-mlogloss:3.74735\n",
      "[89]\tvalidation_0-mlogloss:3.76194\n",
      "[90]\tvalidation_0-mlogloss:3.76217\n",
      "[91]\tvalidation_0-mlogloss:3.76530\n",
      "[92]\tvalidation_0-mlogloss:3.77847\n",
      "[93]\tvalidation_0-mlogloss:3.78721\n",
      "[94]\tvalidation_0-mlogloss:3.79520\n",
      "[95]\tvalidation_0-mlogloss:3.80335\n",
      "[96]\tvalidation_0-mlogloss:3.80591\n",
      "[97]\tvalidation_0-mlogloss:3.81373\n",
      "[98]\tvalidation_0-mlogloss:3.82097\n",
      "[99]\tvalidation_0-mlogloss:3.82979\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder = labelEncoder.fit(np.ravel(train_y))\n",
    "label_encoded_train_y = labelEncoder.transform(np.ravel(train_y))\n",
    "label_encoded_test_y = labelEncoder.transform(np.ravel(test_y))\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,\n",
    "    max_depth=DT_MAX_DEPTH,\n",
    "    n_estimators=DT_NUM_ESTIMATORS,\n",
    ")\n",
    "# fit model\n",
    "xgb.fit(train_x, label_encoded_train_y, eval_set=[(test_x, label_encoded_test_y)])\n",
    "\n",
    "\n",
    "preds = xgb.predict(test_x)\n",
    "accuracy = accuracy_score(label_encoded_test_y, preds)\n",
    "\n",
    "XGBClassifier.save_model(xgb, PATH_MODEL+\"dt.\"+str(round(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f987c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 1s 3ms/step - loss: 0.9004 - accuracy: 0.6606 - val_loss: 1.0207 - val_accuracy: 0.5953\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7988 - val_loss: 1.3973 - val_accuracy: 0.5450\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8342 - val_loss: 2.0212 - val_accuracy: 0.5111\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8565 - val_loss: 2.3167 - val_accuracy: 0.5017\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8765 - val_loss: 2.3918 - val_accuracy: 0.5269\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8843 - val_loss: 2.7863 - val_accuracy: 0.5153\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9014 - val_loss: 2.8136 - val_accuracy: 0.5164\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9143 - val_loss: 2.9690 - val_accuracy: 0.5082\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9216 - val_loss: 2.9043 - val_accuracy: 0.5785\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9366 - val_loss: 3.1016 - val_accuracy: 0.5118\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9287 - val_loss: 3.1998 - val_accuracy: 0.5218\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9394 - val_loss: 3.0162 - val_accuracy: 0.5651\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9385 - val_loss: 2.9197 - val_accuracy: 0.5960\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9444 - val_loss: 3.2499 - val_accuracy: 0.5471\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9456 - val_loss: 3.5795 - val_accuracy: 0.5412\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9504 - val_loss: 3.6302 - val_accuracy: 0.5213\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9449 - val_loss: 3.4481 - val_accuracy: 0.5181\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9382 - val_loss: 3.8803 - val_accuracy: 0.5318\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9468 - val_loss: 4.0392 - val_accuracy: 0.5053\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9473 - val_loss: 4.2577 - val_accuracy: 0.5079\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9582 - val_loss: 4.1900 - val_accuracy: 0.5011\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9570 - val_loss: 4.4731 - val_accuracy: 0.5033\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9632 - val_loss: 4.3101 - val_accuracy: 0.5038\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9594 - val_loss: 4.3684 - val_accuracy: 0.5014\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9625 - val_loss: 4.2405 - val_accuracy: 0.5021\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9565 - val_loss: 4.2689 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 4.3068 - val_accuracy: 0.5003\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9589 - val_loss: 4.4923 - val_accuracy: 0.5001\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9575 - val_loss: 4.5082 - val_accuracy: 0.5001\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9589 - val_loss: 4.3810 - val_accuracy: 0.5004\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9634 - val_loss: 4.6092 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9610 - val_loss: 4.5529 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9653 - val_loss: 4.9003 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9622 - val_loss: 4.7165 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9608 - val_loss: 4.6681 - val_accuracy: 0.5003\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9670 - val_loss: 4.8815 - val_accuracy: 0.5003\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9580 - val_loss: 4.8013 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9675 - val_loss: 4.5455 - val_accuracy: 0.5001\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9651 - val_loss: 4.2004 - val_accuracy: 0.5001\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9660 - val_loss: 4.2737 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9641 - val_loss: 4.6304 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9701 - val_loss: 4.1757 - val_accuracy: 0.5001\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9696 - val_loss: 4.4978 - val_accuracy: 0.5054\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9691 - val_loss: 4.1302 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9701 - val_loss: 4.0377 - val_accuracy: 0.5017\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9656 - val_loss: 3.8071 - val_accuracy: 0.5006\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9660 - val_loss: 4.2440 - val_accuracy: 0.5003\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9743 - val_loss: 4.5723 - val_accuracy: 0.5003\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9651 - val_loss: 4.2878 - val_accuracy: 0.5083\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 4.3093 - val_accuracy: 0.5018\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9736 - val_loss: 3.7391 - val_accuracy: 0.5038\n",
      "132/132 [==============================] - 0s 729us/step - loss: 0.9120 - accuracy: 0.6190\n",
      "225/225 [==============================] - 0s 710us/step - loss: 1.0207 - accuracy: 0.5953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/dnn.1685239363\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/dnn.1685239363\\assets\n"
     ]
    }
   ],
   "source": [
    "# Train Neural Network\n",
    "import json\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "onehotencoder = onehotencoder.fit(train_y)\n",
    "onehot_encoded_train_y = onehotencoder.transform(train_y).toarray()\n",
    "onehot_encoded_test_y = onehotencoder.transform(test_y).toarray()\n",
    "\n",
    "exploration_results = []\n",
    "\n",
    "\n",
    "n_features = train_x.shape[1]\n",
    "categories = len(onehot_encoded_train_y[0])\n",
    "\n",
    "test_acc = 0.0\n",
    "model = Sequential()\n",
    "interation = 0\n",
    "while (\n",
    "    test_acc < DNN_EXPLORATION_TARGET_VAL_ACCURACY\n",
    "    and interation < DNN_EXPLORATION_MAX_ITER\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(n_features,)))\n",
    "    model.add(BatchNormalization())\n",
    "    dense_count = random.randint(\n",
    "        DNN_EXPLORATION_HIDDEN_LAYERS_MIN, DNN_EXPLORATION_HIDDEN_LAYERS_MAX\n",
    "    )\n",
    "    dense_neurons = []\n",
    "    for i in range(0, dense_count):\n",
    "        neurons = random.randint(\n",
    "            DNN_EXPLORATION_NEURONS_MIN, DNN_EXPLORATION_NEURONS_MAX\n",
    "        )\n",
    "        dense_neurons.append(neurons)\n",
    "        model.add(Dense(neurons, activation=\"tanh\"))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(categories, activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.fit(\n",
    "        train_x,\n",
    "        onehot_encoded_train_y,\n",
    "        epochs=DNN_EPOCHS,\n",
    "        batch_size=DNN_BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        validation_data=(test_x, onehot_encoded_test_y),\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=DNN_EARLY_STOPPING_PATIENCE,\n",
    "                restore_best_weights=True,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(train_x, onehot_encoded_train_y)\n",
    "    test_loss, test_acc = model.evaluate(test_x, onehot_encoded_test_y)\n",
    "\n",
    "    exploration_results.append(\n",
    "        {\n",
    "            \"dense_count\": dense_count,\n",
    "            \"dense_neurons\": dense_neurons,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "        }\n",
    "    )\n",
    "    interation += 1\n",
    "\n",
    "modelName = \"dnn.\" + str(round(time.time()))\n",
    "model.save(PATH_MODEL + modelName)\n",
    "\n",
    "with open(PATH_EXPLORATION_DATA + modelName + \".exploration_results.json\", \"w\") as f:\n",
    "    json.dump(exploration_results, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "615dfc90-2798-42fe-8001-7be9ea78aa35",
   "metadata": {},
   "source": [
    "## 6. Modelanalyse des Learners [Kevin]\n",
    "\n",
    "- Vorherige Auswahl eines Learners\n",
    "- Feature Importance\n",
    "- Korrelationsmatrix\n",
    "- Konfusionsmatrix\n",
    "- Post-Validation des Models mit auswählbaren Daten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72ea0d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4e88c5d25e4ec887f6417738be3b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='model', options=('dnn.1685239363', 'dt.1685239368'), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7248a6ae46b3438587107fcfb1a25b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='test data', options=('vib.setup1.csv', 'vib.setup2.csv'), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SELECT LEARNER AND TEST DATA\n",
    "featureDataDir = list(filter(lambda x: os.path.isfile(os.path.join(PATH_FEATURE_DATA, x)) and DEFAULT_RAW_DATA_TYPE in x.upper(), os.listdir(PATH_FEATURE_DATA)))\n",
    "modelDir = os.listdir(PATH_MODEL)\n",
    "\n",
    "modelDropdown = widgets.Dropdown(description=\"model\")\n",
    "modelDropdown.options = modelDir\n",
    "selectedModelFile = None\n",
    "def onTrainigFileChange(change):\n",
    "    global selectedModelFile\n",
    "    selectedModelFile = change['new']\n",
    "modelDropdown.observe(onTrainigFileChange, names='value')\n",
    "display(modelDropdown)\n",
    "\n",
    "testFileDropdown = widgets.Dropdown(description=\"test data\")\n",
    "testFileDropdown.options = featureDataDir\n",
    "selectedTestFile = None\n",
    "def onTestFileChange(change):\n",
    "    global selectedTestFile\n",
    "    selectedTestFile = change['new']\n",
    "testFileDropdown.observe(onTestFileChange, names='value')\n",
    "display(testFileDropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3540ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYZE MODEL\n",
    "from matplotlib import pyplot\n",
    "from tensorflow import math as tfmath\n",
    "import tensorflow_probability as tfp\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "conf_matrix = tfmath.confusion_matrix(np.argmax(y_test, axis=1), np.argmax(result, axis=1))\n",
    "pyplot.matshow(conf_matrix, 1)\n",
    "for (x, y), value in np.ndenumerate(conf_matrix):\n",
    "    pyplot.text(y, x, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "print('Test Accuracy: %.3f' % test_acc)\n",
    "\n",
    "\n",
    "corr_matrix = tfp.stats.correlation(X_test)\n",
    "pyplot.matshow(corr_matrix)\n",
    "pyplot.show()\n",
    "\n",
    "perm = PermutationImportance(model, scoring=\"neg_mean_squared_error\", random_state=1).fit(X_test, y_test)\n",
    "print(eli5.format_as_text(eli5.explain_weights(perm, feature_names=feature_names)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "390a4a00-cdc0-4fae-bd1f-e92cd875dec1",
   "metadata": {},
   "source": [
    "## 7. Statische Interpretation des Resultats\n",
    "\n",
    "- Welches Ergebnis haben wir erzielt und wie kann man es anwenden?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
